{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Runbook: No Release PR Created After Successful KG Release\n",
    "\n",
    "This runbook helps diagnose and fix issues when a KG release workflow succeeds but the automated PR is not created.\n",
    "\n",
    "## Problem\n",
    "The `auto-kg-release` workflow completes successfully, but the expected release PR is not automatically created in the repository.\n",
    "\n",
    "## Root Cause\n",
    "This is typically caused by the Argo Events workflow not triggering properly. The system uses:\n",
    "1. **EventSource**: Watches for succeeded workflows with `trigger_release: \"True\"` label\n",
    "2. **Sensor**: Creates a `distribute-data-release` workflow that triggers a GitHub repository dispatch event\n",
    "3. **GitHub Action**: Creates the release PR\n",
    "\n",
    "## Prerequisites\n",
    "- kubectl configured for the cluster\n",
    "- jq installed for JSON processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Step 1: Identify the Failed Workflow\n",
    "\n",
    "Find the workflow name that succeeded but didn't trigger the release process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List recent workflows, sorted by creation time\n",
    "! gcloud container clusters get-credentials compute-cluster --region us-central1 --project mtrx-hub-dev-3of\n",
    "! kubectl get workflows -n argo-workflows --sort-by=.metadata.creationTimestamp | tail -20\n",
    "\n",
    "# Example workflow name: auto-kg-release-v0-11-4-256629c0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Step 2: Check EventSource and Sensor Status\n",
    "\n",
    "Verify that the Argo Events components are running properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check EventSource status\n",
    "!kubectl get eventsource -n data-release\n",
    "\n",
    "# Check Sensor status\n",
    "!kubectl get sensor -n data-release\n",
    "\n",
    "# Check if pods are running\n",
    "!kubectl get pods -n data-release"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Step 3: Check EventSource Logs\n",
    "\n",
    "Look for errors or issues in the EventSource that watches for workflow completions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View EventSource logs (looking for errors or missed events)\n",
    "!kubectl logs -n data-release -l eventsource-name=build-data-release-eventsource --tail=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Step 4: Check Sensor Logs\n",
    "\n",
    "Check if the sensor received the event and attempted to trigger the distribute workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Sensor logs\n",
    "!kubectl logs -n data-release -l sensor-name=build-data-release-sensor-post-release --tail=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Step 5: Check if Distribute Workflow Was Created\n",
    "\n",
    "The sensor should create a `distribute-data-release-*` workflow when triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for distribute-data-release workflows\n",
    "! kubectl get workflows -n data-release --sort-by=.metadata.creationTimestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "**Note**: If you see a `distribute-data-release-*` workflow was created and shows status `Succeeded`, skip to **Step 9** to check the GitHub Action. Steps 6-8 are only needed if the workflow wasn't created or failed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Step 6: Manual Trigger (Solution)\n",
    "\n",
    "If the event didn't fire automatically, manually trigger it by recreating the workflow with trigger labels.\n",
    "\n",
    "**Important**: Replace `WORKFLOW_NAME` with your actual workflow name (e.g., `auto-kg-release-v0-11-4-256629c0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the workflow name here\n",
    "WORKFLOW_NAME = \"auto-kg-release-v0-12-0-35761b01\"  # REPLACE THIS\n",
    "\n",
    "# Extract version and git SHA from the workflow name\n",
    "# Format: auto-kg-release-vX-Y-Z-GITSHA\n",
    "import re\n",
    "match = re.search(r'v(\\d+-\\d+-\\d+)-([a-f0-9]+)', WORKFLOW_NAME)\n",
    "if match:\n",
    "    version = match.group(1).replace('-', '.')\n",
    "    git_sha = match.group(2)\n",
    "    print(f\"Detected version: v{version}\")\n",
    "    print(f\"Detected git SHA: {git_sha}\")\n",
    "else:\n",
    "    print(\"Warning: Could not parse version and git SHA from workflow name\")\n",
    "    version = \"0.0.0\"\n",
    "    git_sha = \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the workflow with trigger labels\n",
    "# This uses kubectl + jq to copy the workflow and add the required labels\n",
    "!kubectl get workflow {WORKFLOW_NAME} -n argo-workflows -o json | \\\n",
    "  jq 'del(.metadata.uid, .metadata.resourceVersion, .metadata.creationTimestamp, .metadata.managedFields, .status) | \\\n",
    "      .metadata.generateName = \"test-trigger-release-\" | \\\n",
    "      del(.metadata.name) | \\\n",
    "      .metadata.labels[\"trigger_release\"] = \"True\" | \\\n",
    "      .metadata.labels[\"release_version\"] = \"v{version}\" | \\\n",
    "      .metadata.labels[\"git_sha\"] = \"{git_sha}\"' | \\\n",
    "  kubectl create -f -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Step 7: Verify the Trigger Worked\n",
    "\n",
    "Watch for the new workflow to be created and monitor the event flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch for the test workflow to complete\n",
    "!kubectl get workflows -n argo-workflows | grep test-trigger-release\n",
    "\n",
    "# Check if distribute workflow was created\n",
    "!kubectl get workflows -n data-release | grep distribute-data-release | tail -5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Step 8: Check Distribute Workflow Logs\n",
    "\n",
    "If the distribute workflow was created, check its logs to see if the GitHub dispatch succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most recent distribute workflow name\n",
    "distribute_workflow = !kubectl get workflows -n data-release --sort-by=.metadata.creationTimestamp | grep distribute-data-release | tail -1 | awk '{{print $1}}'\n",
    "\n",
    "if distribute_workflow and distribute_workflow[0]:\n",
    "    workflow_name = distribute_workflow[0]\n",
    "    print(f\"Checking logs for: {workflow_name}\")\n",
    "    !kubectl logs -n data-release -l workflows.argoproj.io/workflow={workflow_name} --tail=50\n",
    "else:\n",
    "    print(\"No distribute-data-release workflow found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Step 9: Check GitHub Action (If No Errors Found)\n",
    "\n",
    "If the distribute workflow succeeded but no PR was created, check the upstream GitHub Action that creates the release PR.\n",
    "\n",
    "The GitHub dispatch event triggers this workflow:  \n",
    "**https://github.com/everycure-org/matrix/actions/workflows/create-release-pr.yml**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the GitHub Actions page in your browser\n",
    "import webbrowser\n",
    "\n",
    "github_actions_url = \"https://github.com/everycure-org/matrix/actions/workflows/create-release-pr.yml\"\n",
    "print(f\"Opening GitHub Actions: {github_actions_url}\")\n",
    "print(\"\\nThings to check:\")\n",
    "print(\"1. Look for recent workflow runs triggered by 'distribute-release' event\")\n",
    "print(\"2. Check if any runs failed or are still in progress\")\n",
    "print(\"3. Review logs for any errors in the PR creation process\")\n",
    "print(\"4. Verify the workflow was triggered with correct release_version and git_fingerprint\")\n",
    "\n",
    "# Uncomment the line below to auto-open in browser\n",
    "# webbrowser.open(github_actions_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Alternative: Use GitHub CLI to Check Action Runs\n",
    "\n",
    "If you have the GitHub CLI (`gh`) installed, you can check recent workflow runs directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check recent runs of the create-release-pr workflow\n",
    "!gh run list --repo everycure-org/matrix --workflow=create-release-pr.yml --limit 10\n",
    "\n",
    "# To view logs of a specific run (replace RUN_ID with the actual ID from above)\n",
    "# !gh run view RUN_ID --repo everycure-org/matrix --log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Common Issues and Solutions\n",
    "\n",
    "### Issue 1: EventSource not detecting workflows\n",
    "**Symptom**: No logs in EventSource showing workflow detection  \n",
    "**Solution**: Check RBAC permissions on the `data-release-service-account`\n",
    "\n",
    "### Issue 2: Sensor not triggering workflow\n",
    "**Symptom**: EventSource sees the workflow, but Sensor doesn't create distribute workflow  \n",
    "**Solution**: Check Sensor logs for permission errors or missing parameters\n",
    "\n",
    "### Issue 3: Distribute workflow fails\n",
    "**Symptom**: Workflow created but GitHub dispatch fails  \n",
    "**Solution**: Check the `gh-password` secret has valid GitHub token\n",
    "\n",
    "### Issue 4: GitHub Action doesn't create PR\n",
    "**Symptom**: Dispatch succeeds but no PR created  \n",
    "**Solution**: Check GitHub Actions tab in the repository for workflow errors\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "After running this runbook:\n",
    "1. Monitor the GitHub repository for the release PR to appear\n",
    "2. If still no PR, check GitHub Actions workflow runs\n",
    "3. Consider investigating why the original workflow didn't have trigger labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Testing: Trigger Large Payload Test Workflow\n",
    "\n",
    "To test NATS payload size limits and verify the EventBus configuration handles large workflow objects (e.g., after fixing `maxPayload` settings), you can create a test workflow with a ~1.3 MB payload.\n",
    "\n",
    "This is useful for:\n",
    "- Verifying NATS `maxPayload` configuration is applied correctly\n",
    "- Testing EventSource `payloadFilter` is working\n",
    "- Reproducing \"nats: maximum payload exceeded\" errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a test workflow with ~1.3 MB payload (exceeds default 1MB NATS limit)\n",
    "import json\n",
    "import random\n",
    "\n",
    "workflow = {\n",
    "    \"apiVersion\": \"argoproj.io/v1alpha1\",\n",
    "    \"kind\": \"Workflow\",\n",
    "    \"metadata\": {\n",
    "        \"generateName\": f\"test-large-payload-1-5mb-{random.randint(1000, 9999)}-\",\n",
    "        \"namespace\": \"argo-workflows\",\n",
    "        \"labels\": {\n",
    "            \"trigger_release\": \"True\",\n",
    "            \"workflows.argoproj.io/phase\": \"Succeeded\",\n",
    "            \"release_version\": \"v0.99.99-test\",\n",
    "            \"git_sha\": \"test123456\"\n",
    "        }\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"entrypoint\": \"main\",\n",
    "        \"templates\": [\n",
    "            {\n",
    "                \"name\": \"main\",\n",
    "                \"container\": {\n",
    "                    \"image\": \"alpine:latest\",\n",
    "                    \"command\": [\"echo\", \"Testing large payload\"]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"status\": {\n",
    "        \"phase\": \"Succeeded\",\n",
    "        \"startedAt\": \"2025-11-04T00:00:00Z\",\n",
    "        \"finishedAt\": \"2025-11-04T00:01:00Z\",\n",
    "        \"storedTemplates\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add large dummy data to reach ~1.3MB\n",
    "dummy_data = \"x\" * 75000  # 75KB chunks\n",
    "\n",
    "for i in range(18):  # 18 * 75KB = ~1.35MB\n",
    "    template = {\n",
    "        \"name\": f\"large-template-{i}\",\n",
    "        \"container\": {\n",
    "            \"image\": \"dummy:latest\",\n",
    "            \"command\": [\"sh\", \"-c\"],\n",
    "            \"args\": [dummy_data]\n",
    "        }\n",
    "    }\n",
    "    workflow[\"status\"][\"storedTemplates\"].append(template)\n",
    "\n",
    "# Save to file\n",
    "with open('/tmp/test-large-payload-workflow.json', 'w') as f:\n",
    "    json.dump(workflow, f, indent=2)\n",
    "\n",
    "import os\n",
    "size = os.path.getsize('/tmp/test-large-payload-workflow.json')\n",
    "print(f\"Generated test workflow: {size:,} bytes ({size/1024/1024:.2f} MB)\")\n",
    "print(f\"This is {size/1048576:.1f}x the default 1MB NATS limit\")\n",
    "print(f\"\\nFile saved to: /tmp/test-large-payload-workflow.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the test workflow to the cluster\n",
    "!kubectl create -f /tmp/test-large-payload-workflow.json\n",
    "\n",
    "# Note: This should succeed in creating the workflow\n",
    "# The test is whether the EventSource can publish this large event to NATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check EventSource logs for success or \"maximum payload exceeded\" error\n",
    "!kubectl logs -n data-release -l eventsource-name=build-data-release-eventsource --tail=10\n",
    "\n",
    "# Expected results:\n",
    "# - If NATS limit is too small (default 1MB): \"error\":\"failed after retries: nats: maximum payload exceeded\"\n",
    "# - If payloadFilter is working: \"Succeeded to publish an event\"\n",
    "# - If maxPayload is properly configured: \"Succeeded to publish an event\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Cleanup Test Workflow\n",
    "\n",
    "After testing, clean up the test workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete test workflows\n",
    "!kubectl delete workflow -n argo-workflows -l release_version=v0.99.99-test\n",
    "\n",
    "# Also clean up any triggered distribute workflows (if any were created)\n",
    "!kubectl delete workflow -n data-release -l app=distribute-data-release --field-selector metadata.name!=auto-*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matrix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
