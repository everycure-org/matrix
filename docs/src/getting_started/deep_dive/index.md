---
title: Deep Dive
---

# Deep Dive into MATRIX

After completing first steps, you should be able to:
- Understand our on a high level Tech Stack
- Set up MATRIX environment on your machine
- Run the Repurposing Pipeline with both fabricated data and sample of real data

In this section, we will walk through our tech stack and pipeline in more detail. 

After completing this section, you should be able to:
- Understand our custom Kedro extensions and how they are utilized in our pipeline
- Understand our CI/CD pipelines and how are they orchestrated with GCP
- Run the Repurposing Pipeline on real data of choice using our Kubernetes Cluster & Argo Workflows
- How to utilize data fabricator for easier development
- How to introduce a new data source into our pipeline
- How to develop a custom model in a notebook whilst using our pipeline & pipeline data products

