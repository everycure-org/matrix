{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Notebook for easy access to the Matrix Knowledge Graph for notebook based model development\n",
    "\n",
    "*Note you can change this notebook because changes are not tracked by git.*\n",
    "\n",
    "Let's first get you set up with git so you can also pull new changes from the repo easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_username = input(\"Please enter your github username: \")\n",
    "gh_token = input(\"Please enter your github token: \")\n",
    "\n",
    "# Set GitHub credentials in the remote URL\n",
    "import subprocess\n",
    "# Construct the URL with credentials\n",
    "remote_url = f\"https://{gh_username}:{gh_token}@github.com/everycure-org/matrix.git\"\n",
    "subprocess.run([\"git\", \"remote\", \"set-url\", \"origin\", remote_url], check=True)\n",
    "print(\"Git remote URL updated successfully with your credentials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loads various objects into the context, see \n",
    "# https://docs.kedro.org/en/stable/notebooks_and_ipython/kedro_and_notebooks.html#kedro-line-magics\n",
    "import os\n",
    "# RELEASE_VERSION = \"v0.3.0\" #change the release version here easily\n",
    "# os.environ[\"RELEASE_VERSION\"] = RELEASE_VERSION\n",
    "\n",
    "%load_ext kedro.ipython\n",
    "%reload_kedro  --env cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option A) Accessing datasets easily through the catalog\n",
    "\n",
    "To access the kedro catalog now, simply call `catalog` in a cell and see the list of available datasets.\n",
    "\n",
    "```python\n",
    "catalog.list(\"unified\") # this function accepts any regular expression\n",
    "```\n",
    "\n",
    "> **Note it does not show dynamic datasets like `integration.int.{source}.edges`. This is a known issue we are trying to solve. You can still access them however by calling `catalog.load(\"integration.int.robokop.edges\")` for example\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = catalog.load(\"data_release.prm.bigquery_edges\")\n",
    "edges = catalog.load(\"data_release.prm.bigquery_nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.groupBy(\"upstream_data_source\").count().show()\n",
    "edges.groupBy(\"upstream_data_source\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option B) Access data through BigQuery queries  \n",
    "\n",
    "Note these queries are run on BigQuery and only the results are loaded into the notebook. The results are loaded as pandas dataframes. This has the upside that you can easily reduce the data to the columns and rows you need. The downside is that you cannot simply load the entire dataset into memory. Pandas just cannot handle the size.\n",
    "\n",
    "Check the [BigQuery SQL documentation](https://cloud.google.com/bigquery/docs/introduction-sql) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery nodes_upstream_sources_count\n",
    "SELECT upstream_data_source, count(*) as count FROM `mtrx-hub-dev-3of.release_v0_3_0.nodes` GROUP BY upstream_data_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option C) Access data directly on GCS\n",
    "\n",
    "Some people want to side-step the catalog / bigquery and work directly on the GCS data. \n",
    "The below cell show how you can do this. We use polars for this example but you can use any other library you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install polars\n",
    "import polars as pl\n",
    "\n",
    "df = pl.scan_parquet(\"gs://mtrx-us-central1-hub-dev-storage/kedro/data/releases/v0.3.0/datasets/release/prm/bigquery_nodes/*.parquet\")\n",
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
