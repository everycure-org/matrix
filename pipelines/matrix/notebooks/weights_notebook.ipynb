{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check on weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** we need to avoid inputting drug-disease edges from our KG before inputting them to GraphSAGE to avoid data leakage. One solution was to assign zero-weights to drug-disease edges through GDS - this is beneficial from visualisation perspective. However we were unsure if zero-weighted drug-disease edges definitely dont provide any signal to GraphSAGE (e.g. are zero-weighted edges counted when calculating node degrees?). So here we examine if zero-weighted edges are equivalent to complete removal of edges.\n",
    "\n",
    "**Reproduction:** to reproduce the workflow, follow commit history in this branch:\n",
    "* step1 - codebase where drug-disease edges are assigned weight 0 in GDS; \n",
    "* step2 - codebase where all edges are assigned weight 1 in GDS;\n",
    "* step3 - codebase where we assign zero weights to drug-disease edges AND we remove drug-disease edges; \n",
    "* step4 - codebase where all edges are assigned weight 1 AND we remove drug-disease edges; \n",
    "* step5 - codebase where we dont assign any weights to edges AND we also do remove drug-disease edges;\n",
    "* step6 - codebase where we dont assign any weights to edges AND we also don't remove drug-disease edges;\n",
    "\n",
    "Step3 and step4 are a bit redundant I realize so the most essential are step 1,2,5,6 \n",
    "\n",
    "The embeddings were obtained by simply running\n",
    "```\n",
    "Make wipe_neo\n",
    "kedro run -p integration --env base \n",
    "kedro run -p embeddings --env base\n",
    "```\n",
    "and then saving the output for the embeddings (`embeddings.model_output.graphsage` in `embeddings/catalog.yml`, I did it through ipython/jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pyspark as ps\n",
    "import os\n",
    "import  prince\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from pyspark.sql.functions import col, when\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import umap\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ReadSavedDataFrame\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load output of graphsage (calculated embeddings) - I will upload them to gdrive if anyone is interesed - https://drive.google.com/drive/folders/1noAkqyU0rNaczTFp8ED_2wORtjbJmnMR - embed data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare\n",
    "step1=spark.read.parquet('../scratch/embed_data/step1').select('topological_embedding').toPandas()\n",
    "step2=spark.read.parquet('../scratch/embed_data/step2').select('topological_embedding').toPandas()\n",
    "step3=spark.read.parquet('../scratch/embed_data/step3').select('topological_embedding').toPandas()\n",
    "step4=spark.read.parquet('../scratch/embed_data/step4').select('topological_embedding').toPandas()\n",
    "step5=spark.read.parquet('../scratch/embed_data/step5').select('topological_embedding').toPandas()\n",
    "step6=spark.read.parquet('../scratch/embed_data/step6').select('topological_embedding').toPandas()\n",
    "\n",
    "#extra steps with custom weights \n",
    "step7=spark.read.parquet('../scratch/embed_data/step7').select('topological_embedding').toPandas()\n",
    "step8=spark.read.parquet('../scratch/embed_data/step8').select('topological_embedding').toPandas()\n",
    "step9=spark.read.parquet('../scratch/embed_data/step9').select('topological_embedding').toPandas()\n",
    "step10=spark.read.parquet('../scratch/embed_data/step10').select('topological_embedding').toPandas()\n",
    "\n",
    "#interested mainly in the visualisation part so creating emb objects here\n",
    "emb7= np.array([np.array(i) for i in step7.topological_embedding.values])\n",
    "emb8 = np.array([np.array(i) for i in step8.topological_embedding.values])\n",
    "emb9 = np.array([np.array(i) for i in step9.topological_embedding.values])\n",
    "emb10 = np.array([np.array(i) for i in step10.topological_embedding.values])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the zero-weighted edges are equivalent to not having edges, then embeddings from step1, step3, and step5 should be the same, while embeddings from step2, step4, and step5 should be equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(step1.equals(step3))\n",
    "print(step1.equals(step5))\n",
    "print(step3.equals(step5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not what I expected, lets check further \n",
    "\n",
    "Step2 (when all weights are the same and all edges are present) should be equivalent to step6 (when no weighting is applied and all edges are present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(step2.equals(step6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare step 1,3,5\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "emb1 = np.array([np.array(i) for i in step1.topological_embedding.values])\n",
    "\n",
    "emb3 = np.array([np.array(i) for i in step3.topological_embedding.values])\n",
    "\n",
    "emb5 = np.array([np.array(i) for i in step5.topological_embedding.values])\n",
    "\n",
    "\n",
    "similarities = cosine_similarity(emb1, emb3)\n",
    "print(np.mean(similarities))\n",
    "similarities = cosine_similarity(emb1, emb5)\n",
    "print(np.mean(similarities))\n",
    "similarities = cosine_similarity(emb3, emb5)\n",
    "print(np.mean(similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare step2 with step5 (all weighted 1 and no edges removed respectively)\n",
    "\n",
    "emb2 = np.array([np.array(i) for i in step2.topological_embedding.values])\n",
    "\n",
    "emb4 = np.array([np.array(i) for i in step4.topological_embedding.values])\n",
    "\n",
    "emb6 = np.array([np.array(i) for i in step6.topological_embedding.values])\n",
    "\n",
    "similarities = cosine_similarity(emb2, emb4)\n",
    "print(np.mean(similarities))\n",
    "similarities = cosine_similarity(emb2, emb6)\n",
    "print(np.mean(similarities))\n",
    "similarities = cosine_similarity(emb4, emb6)\n",
    "print(np.mean(similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check difference between step1 and 2 as well as 5 and 6\n",
    "similarities = cosine_similarity(emb1, emb2)\n",
    "print(np.mean(similarities))\n",
    "similarities = cosine_similarity(emb3, emb4)\n",
    "print(np.mean(similarities))\n",
    "similarities = cosine_similarity(emb5, emb6)\n",
    "print(np.mean(similarities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although cosine might not be the best metric it shows how greatly different they are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(emb1, axis=1))\n",
    "pd.DataFrame(emb1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(emb2, axis=1))\n",
    "pd.DataFrame(emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(emb3, axis=1))\n",
    "pd.DataFrame(emb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(emb4, axis=1))\n",
    "pd.DataFrame(emb4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(emb5, axis=1))\n",
    "pd.DataFrame(emb5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(emb6, axis=1))\n",
    "pd.DataFrame(emb6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_list =[emb1,emb2,emb3,emb4,emb5,emb6]\n",
    "print('1 - zero-weighted edges; 2 - one-weighted edges; 3 - zero weighted edges + rm; 4 - one-weighted edges + rm; 5 - rm edges, no weights; 6 - all edges, no weights')\n",
    "plt.subplots(1,6, figsize=(20, 5), sharex=True)\n",
    "for i, emb in enumerate(emb_list, start=1):\n",
    "    plt.subplot(1,6,i)\n",
    "    plt.title(f'setup {i}')\n",
    "    plt.hist(emb, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_list =[emb1,emb2,emb3,emb4,emb5,emb6]\n",
    "print('1 - zero-weighted edges; 2 - one-weighted edges; 3 - zero weighted edges + rm; 4 - one-weighted edges + rm; 5 - rm edges, no weights; 6 - all edges, no weights')\n",
    "plt.subplots(1,6, figsize=(10, 6)) #, sharey=True, sharex=True)\n",
    "for i, emb in enumerate(emb_list, start=1):\n",
    "    plt.subplot(1,6,i)\n",
    "    plt.title(f'setup {i}')\n",
    "    pca = prince.PCA(n_components=2)\n",
    "    result = pca.fit_transform(pd.DataFrame(emb))\n",
    "    plt.scatter(result[0], result[1], alpha=0.5)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('PC 2')\n",
    "    plt.grid(True)\n",
    "plt.suptitle('PC 1',y=0.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#idea - change weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same axes\n",
    "emb_list =[emb1,emb2,emb3,emb4,emb5,emb6]\n",
    "print('1 - zero-weighted edges; 2 - one-weighted edges; 3 - zero weighted edges + rm; 4 - one-weighted edges + rm; 5 - rm edges, no weights; 6 - all edges, no weights')\n",
    "plt.subplots(1,6, figsize=(10, 6), sharey=True, sharex=True)\n",
    "for i, emb in enumerate(emb_list, start=1):\n",
    "    plt.subplot(1,6,i)\n",
    "    plt.title(f'setup {i}')\n",
    "    pca = prince.PCA(n_components=2)\n",
    "    result = pca.fit_transform(pd.DataFrame(emb))\n",
    "    plt.scatter(result[0], result[1], alpha=0.5)\n",
    "    plt.xlabel('PC 1')\n",
    "    plt.ylabel('PC 2')\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check additional 3 steps with 0.2 0.5 and 0.7 weights\n",
    "# same axes\n",
    "emb_list ={1:['weight=0',emb1], 2:['weight=0.25',emb7],3:['weight=0.5',emb8],4:['weight=0.75',emb9],5:['weight=0.9',emb10], 6:['weight=1',emb2]}\n",
    "plt.subplots(1,6, figsize=(10, 6), sharey=True, sharex=True)\n",
    "for id in emb_list.keys():\n",
    "    plt.subplot(1,6,id)\n",
    "    plt.title(f'{emb_list[id][0]}')\n",
    "    pca = prince.PCA(n_components=2)\n",
    "    result = pca.fit_transform(pd.DataFrame(emb_list[id][1]))\n",
    "    plt.scatter(result[0], result[1], alpha=0.5)\n",
    "    plt.xlabel('PC 1')\n",
    "    plt.ylabel('PC 2')\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no treat edges\n",
    "dist = distance.cdist(emb1, emb3, 'euclidean')\n",
    "print('Mean', np.mean(dist), 'STD',np.std(dist))\n",
    "#print(dist, '\\n')\n",
    "dist = distance.cdist(emb1, emb5, 'euclidean')\n",
    "print('Mean', np.mean(dist), 'STD',np.std(dist))\n",
    "#print(dist, '\\n')\n",
    "dist = distance.cdist(emb3, emb5, 'euclidean')\n",
    "print('Mean', np.mean(dist), 'STD',np.std(dist))\n",
    "#print(dist, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treat edges\n",
    "dist = distance.cdist(emb2, emb4, 'euclidean')\n",
    "print('Mean', np.mean(dist), 'STD',np.std(dist))\n",
    "#print(dist, '\\n')\n",
    "dist = distance.cdist(emb2, emb6, 'euclidean')\n",
    "print('Mean', np.mean(dist), 'STD',np.std(dist))\n",
    "#print(dist, '\\n')\n",
    "dist = distance.cdist(emb4, emb6, 'euclidean')\n",
    "print('Mean', np.mean(dist), 'STD',np.std(dist))\n",
    "#print(dist, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra checks\n",
    "dist = distance.cdist(emb1, emb2, 'euclidean')\n",
    "print('Mean', np.mean(dist), 'STD',np.std(dist))\n",
    "#print(dist, '\\n')\n",
    "dist = distance.cdist(emb3, emb4, 'euclidean')\n",
    "print('Mean', np.mean(dist), 'STD',np.std(dist))\n",
    "#print(dist, '\\n')\n",
    "dist = distance.cdist(emb5, emb6, 'euclidean')\n",
    "print('Mean', np.mean(dist), 'STD',np.std(dist))\n",
    "#print(dist, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion so far: the embeddings that we got from setup 1 are very different from remaining setups. For remaining setups, the differences are very subtle. There are two possible scenarios:\n",
    "* the effect of zero-weights is quite large on embedding calculation which is why the difference between setup1 and remaining is large (likely but why?)\n",
    "* something went wrong with removing the edges and generating embeddings (unlikely - checked the code, neo4j does show lack of edges in graph data science projection and all the checks work)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piotr_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
