{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98627c92-503b-4509-a176-68a7305df6a8",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4effb0cd-aba7-4676-9139-13c1a408d33b",
   "metadata": {},
   "source": [
    "# Data Fabricator\n",
    "\n",
    "The data fabricator utility was created to enable mocking a set of tables declaratively,\n",
    "where join integrity between tables are easy to define and maintain. This enables\n",
    "full integration tests of pipelines to be conducted and scaled without manually\n",
    "crafting single data points for every single table.\n",
    "\n",
    "Many libraries such as [faker](https://github.com/joke2k/faker),\n",
    "[hypothesis](https://github.com/HypothesisWorks/hypothesis/tree/master/hypothesis-python),\n",
    "or even the newer [GAN](https://github.com/sdv-dev/TGAN) based approaches\n",
    "address the issue of mocking a **single** table realistically or rely on having a\n",
    "dataset beforehand. `data_fabricator` works without the need for real data, only knowledge \n",
    "of such.\n",
    "\n",
    "## Simple Example\n",
    "\n",
    "Let's say we want to mock the following set of tables and their relationships:\n",
    "![Excel file](images/simple_erd.png)\n",
    "\n",
    "\n",
    "The data fabricator configuration will look like:  \n",
    "\n",
    "### YAML API\n",
    "\n",
    "Example YAML API syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f0eed0-3ecc-4bcd-b550-92b0c04e0444",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```yaml\n",
       "tables:\n",
       "  - _target_: data_fabricator.v1.core.mock_generator.create_table\n",
       "    name: classes\n",
       "    columns:\n",
       "      student_id:\n",
       "        _metadata_:\n",
       "          foreign_key: True\n",
       "        _target_: data_fabricator.v1.core.mock_generator.RowApply\n",
       "        list_of_values: \"students.student_id\"\n",
       "        row_func: \"lambda x:x\"\n",
       "      course:\n",
       "        _target_: data_fabricator.v1.core.mock_generator.RowApply\n",
       "        list_of_values: \"faculty.course\"\n",
       "        row_func: \"lambda x:x\"\n",
       "        resize: True\n",
       "\n",
       "  - _target_: data_fabricator.v1.core.mock_generator.create_table\n",
       "    name: faculty\n",
       "    num_rows: 5\n",
       "    columns:\n",
       "      faculty_id:\n",
       "        _metadata_:\n",
       "          primary_key: True\n",
       "        _target_: data_fabricator.v1.core.mock_generator.UniqueId\n",
       "      name:\n",
       "        _target_: data_fabricator.v1.core.mock_generator.Faker\n",
       "        provider: name\n",
       "        faker_seed: 1\n",
       "      course:\n",
       "        _target_: data_fabricator.v1.core.mock_generator.ValuesFromSamples\n",
       "        sample_values: [\"engineering\", \"computer science\", \"mathematics\"]\n",
       "\n",
       "  - _target_: data_fabricator.v1.core.mock_generator.create_table\n",
       "    name: students\n",
       "    num_rows: 10\n",
       "    columns:\n",
       "      enrollment_date:\n",
       "        end_dt: \"2022-12-31\"\n",
       "        freq: M\n",
       "        _target_: data_fabricator.v1.core.mock_generator.Date\n",
       "        start_dt: \"2021-01-01\"\n",
       "      name:\n",
       "        _target_: data_fabricator.v1.core.mock_generator.Faker\n",
       "        provider: name\n",
       "        faker_seed: 1\n",
       "      student_id:\n",
       "        _metadata_:\n",
       "          primary_key: True\n",
       "        _target_: data_fabricator.v1.core.mock_generator.UniqueId\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "yaml_path = \"tests/v1/scenarios/scenario2/single_yaml_config.yml\"\n",
    "with open(yaml_path, \"r\") as yaml_file:\n",
    "    yaml_string = yaml_file.read()\n",
    "    display(Markdown(\"\\n\".join([\"```yaml\", yaml_string, \"```\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee42578b-56f4-4339-a8f5-5bba73eb82a3",
   "metadata": {},
   "source": [
    "See [02_kedro_integration](02_kedro_integration.md) for more details. \n",
    "\n",
    "Hopefully, that was intuitive and easy to follow! Some intricacies are explained in the\n",
    "following sections.\n",
    "\n",
    "### Python API\n",
    "\n",
    "Define "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e125fb-9740-4762-b17a-bd38c8e2f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_fabricator.v1.core.mock_generator import (\n",
    "    BaseTable,\n",
    "    Date,\n",
    "    Faker,\n",
    "    RowApply,\n",
    "    UniqueId,\n",
    "    ValuesFromSamples,\n",
    ")\n",
    "\n",
    "\n",
    "class Students(BaseTable):\n",
    "    num_rows = 10\n",
    "    _metadata_ = {\n",
    "        \"description\": \"Student table with enrollment info\",\n",
    "    }\n",
    "    student_id = UniqueId()\n",
    "    name = Faker(provider=\"name\", faker_seed=1)\n",
    "    enrollment_date = Date(start_dt=\"2019-01-01\", end_dt=\"2020-12-31\", freq=\"M\")\n",
    "\n",
    "\n",
    "class Faculty(BaseTable):\n",
    "    num_rows = 5\n",
    "    _metadata_ = {\n",
    "        \"description\": \"Faculty info along with departments\",\n",
    "    }\n",
    "    faculty_id = UniqueId()\n",
    "    name = Faker(provider=\"name\", faker_seed=1)\n",
    "    course = ValuesFromSamples(\n",
    "        sample_values=[\"engineering\", \"computer science\", \"mathematics\"],\n",
    "        prob_null_kwargs={\"seed\": 1},\n",
    "    )\n",
    "\n",
    "\n",
    "class Classes(BaseTable):\n",
    "    student_id = RowApply(list_of_values=\"Students.student_id\", row_func=lambda x: x)\n",
    "    course = RowApply(\n",
    "        list_of_values=\"Faculty.course\", row_func=lambda x: x, resize=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa6eab-7202-4879-9e83-35a3bbbeabb3",
   "metadata": {},
   "source": [
    "In order to generate the data, perform the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c2bd761-48c9-4b23-8414-9d7b2be4d263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing list from 5 to 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: Classes\n",
      "+----+--------------+------------------+\n",
      "|    |   student_id | course           |\n",
      "|----+--------------+------------------|\n",
      "|  0 |            1 | mathematics      |\n",
      "|  1 |            2 | mathematics      |\n",
      "|  2 |            3 | computer science |\n",
      "|  3 |            4 | engineering      |\n",
      "|  4 |            5 | engineering      |\n",
      "|  5 |            6 | computer science |\n",
      "|  6 |            7 | mathematics      |\n",
      "|  7 |            8 | computer science |\n",
      "|  8 |            9 | engineering      |\n",
      "|  9 |           10 | mathematics      |\n",
      "+----+--------------+------------------+\n",
      "\n",
      "\n",
      "Table: Faculty\n",
      "+----+------------------+--------------+------------------+\n",
      "|    | course           |   faculty_id | name             |\n",
      "|----+------------------+--------------+------------------|\n",
      "|  0 | engineering      |            1 | Ryan Gallagher   |\n",
      "|  1 | mathematics      |            2 | Jon Cole         |\n",
      "|  2 | mathematics      |            3 | Rachel Davis     |\n",
      "|  3 | engineering      |            4 | Russell Reynolds |\n",
      "|  4 | computer science |            5 | April Griffin    |\n",
      "+----+------------------+--------------+------------------+\n",
      "\n",
      "\n",
      "Table: Students\n",
      "+----+--------------+------------------+---------------------+\n",
      "|    |   student_id | name             | enrollment_date     |\n",
      "|----+--------------+------------------+---------------------|\n",
      "|  0 |            1 | Ryan Gallagher   | 2019-01-31 00:00:00 |\n",
      "|  1 |            2 | Jon Cole         | 2019-04-30 00:00:00 |\n",
      "|  2 |            3 | Rachel Davis     | 2019-08-31 00:00:00 |\n",
      "|  3 |            4 | Russell Reynolds | 2019-11-30 00:00:00 |\n",
      "|  4 |            5 | April Griffin    | 2020-03-31 00:00:00 |\n",
      "|  5 |            6 | Crystal Landry   | 2020-05-31 00:00:00 |\n",
      "|  6 |            7 | Amanda Johnson   | 2020-06-30 00:00:00 |\n",
      "|  7 |            8 | Teresa James     | 2020-07-31 00:00:00 |\n",
      "|  8 |            9 | Javier Johnson   | 2020-10-31 00:00:00 |\n",
      "|  9 |           10 | Jeffrey Simpson  | 2020-12-31 00:00:00 |\n",
      "+----+--------------+------------------+---------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "from data_fabricator.v1.core.mock_generator import MockDataGenerator\n",
    "\n",
    "mdg = MockDataGenerator(tables=[Classes, Faculty, Students])\n",
    "mdg.generate_all()\n",
    "\n",
    "for table_name, table in mdg.tables.items():\n",
    "    print(f\"Table: {table_name}\")\n",
    "    print(tabulate(table.dataframe, headers=table.dataframe.columns, tablefmt=\"psql\"))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f002fdb0-151c-4bf0-99dd-cb99b12a73ec",
   "metadata": {},
   "source": [
    "## V1 API Summary\n",
    "\n",
    "- Dual Python/YAML API. Python/code API allows for IDE autocomplete.\n",
    "- Resolves table generation independently of the order, which means tables no \n",
    "    longer need to be declared02 in order.\n",
    "- Supports multiple config files, which helps break down bigger sets of tables into smaller \n",
    "    more manageable pieces.\n",
    "- YAML API means `data_fabricator` is also compatible with other configuration management \n",
    "    systems like `Hydra`.\n",
    "- Allows for capturing table and column level metadata under the `_metadata_` field for \n",
    "    better documentation support. \n",
    "- Various quality-of-life changes for less typing and more doing. \n",
    "\n",
    "## Configuration Structure\n",
    "\n",
    "There are 2 ways one can use the `data_fabricator` module: the Python API and the YAML API.\n",
    "\n",
    "### Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9d82b4-7e83-4a0c-9eeb-e23a3d930f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table1(BaseTable):\n",
    "    num_rows: ...\n",
    "    _metadata_ = {\n",
    "        \"description\": \"...\",\n",
    "    }\n",
    "    column_a: ...\n",
    "    column_b: ...\n",
    "    column_c: ...\n",
    "\n",
    "\n",
    "class Table2(BaseTable):\n",
    "    num_rows: ...\n",
    "    _metadata_ = {\n",
    "        \"description\": \"...\",\n",
    "    }\n",
    "    column_a: ...\n",
    "    column_b: ...\n",
    "    column_c: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88520c3-42eb-40ef-b522-9c4f750fc652",
   "metadata": {},
   "source": [
    "### YAML API\n",
    "\n",
    "Note this API syntax may change if you bring your own DI framework. The following \n",
    "examples uses the Hydra instantiation which relies on the `_target_` keyword.\n",
    "\n",
    "```yaml\n",
    "tables:\n",
    "  - _target_: data_fabricator.v1.core.mock_generator.create_table\n",
    "    name: table1\n",
    "    num_rows: ...\n",
    "    _metadata_: \n",
    "      description: ...\n",
    "    columns:\n",
    "      column_a: ...\n",
    "      column_b: ...\n",
    "      column_c: ...\n",
    "\n",
    "  - _target_: data_fabricator.v1.core.mock_generator.create_table\n",
    "    name: table2\n",
    "    num_rows: ...\n",
    "    _metadata_: \n",
    "      description: ...\n",
    "    columns:\n",
    "      column_a: ...\n",
    "      column_b: ...\n",
    "      column_c: ...\n",
    "```\n",
    "\n",
    "A few points to note:\n",
    "* Every table is represented by an object injected with `create_table` that returns \n",
    "a dataclass exactly like the one declared with Python API.\n",
    "* Every column for that table is represented as a key under `columns`.\n",
    "* All the columns for the particular table are explicitly declared. \n",
    "* The `_metadata_` field also allow other information about table like description. \n",
    "* Depending on the context, `num_rows` may be inferred.\n",
    "\n",
    "\n",
    "## Migration Guide from V0 to V1\n",
    "\n",
    "If you are using the `v0` API, you can simply install the new version. The `v1` API will \n",
    "exist side-by-side with the `v0` API. You can slowly convert one function at a time from \n",
    "the `v0` API to the `v1` API. \n",
    "\n",
    "Most of the changes would be porting from the old structure to the `v1` YAML API. As \n",
    "an illustration, we provide a before and after comparison below. \n",
    "\n",
    "Before:\n",
    "```yaml\n",
    "  customers:\n",
    "    num_rows: 10\n",
    "    columns:\n",
    "      hcp_id:\n",
    "        type: generate_unique_id\n",
    "        prefix: hcp\n",
    "        id_start_range: 1\n",
    "        id_end_range: 11\n",
    "      ftr1:\n",
    "        type: generate_random_numbers\n",
    "        start_range: 0\n",
    "        end_range: 1\n",
    "        prob_null: 0.25\n",
    "  ```\n",
    "\n",
    "After:\n",
    "```yaml\n",
    "customers:\n",
    "  - _target_: data_fabricator.v1.core.mock_generator.create_table\n",
    "    name: customers\n",
    "    num_rows: 10\n",
    "    columns:\n",
    "      hcp_id:\n",
    "        _target_: data_fabricator.v1.core.mock_generator.PrimaryKey\n",
    "        prefix: hcp\n",
    "        id_start_range: 1\n",
    "        id_end_range: 11\n",
    "      ftr1:\n",
    "        _target_: data_fabricator.v1.core.mock_generator.RandomNumbers\n",
    "        start_range: 0\n",
    "        end_range: 1\n",
    "        prob_null_kwargs: \n",
    "          prob_null: 0.25\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77701ba-d6bc-46a9-b7f4-8541beb7067f",
   "metadata": {},
   "source": [
    "A `v0_converter` function is provided in the package `data_fabricator.v1.utils` to facilitate the transition. It can convert the functions that are implemented both in `v0` and `v1`. \n",
    "\n",
    "It's important to note that it won't correctly migrate the functions that had undergone implementation changes in `v1`. For example, functions `drop_filtered_condition_rows` , `cross_product`, `drop_duplicates`.\n",
    "\n",
    "In these cases, it may be necessary to manually modify the code to account for any changes in implementation between `v0` and `v1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e714ab-90c6-4524-81f4-6e3529879e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_fabricator.v1.utils import v0_converter\n",
    "\n",
    "yaml_string = \"\"\"\n",
    "students:\n",
    "  num_rows: 10\n",
    "  columns:\n",
    "    student_id:\n",
    "      type: generate_unique_id\n",
    "      seed: 1 # defaults to None\n",
    "      prob_null: 0.5 # defaults to 0\n",
    "      null_value: unassigned # defaults to None\n",
    "\"\"\"\n",
    "config = yaml.safe_load(yaml_string)\n",
    "config = v0_converter(config)\n",
    "v1_string = yaml.safe_dump(config, default_flow_style=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c188fdb-23ca-4f0d-aac1-4b7b22de6dee",
   "metadata": {},
   "source": [
    "Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e4e881-db54-4456-85f0-ff220ee4650c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```yaml\n",
       "tables:\n",
       "- _target_: data_fabricator.v1.core.mock_generator.create_table\n",
       "  name: students\n",
       "  num_rows: 10\n",
       "  columns:\n",
       "    student_id:\n",
       "      _target_: data_fabricator.v1.core.mock_generator.UniqueId\n",
       "      prob_null_kwargs:\n",
       "        prob_null: 0.5\n",
       "        null_value: unassigned\n",
       "        seed: 1\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"\\n\".join([\"```yaml\", v1_string, \"```\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c87adae-4421-4d7d-9c26-5c32c87f9196",
   "metadata": {},
   "source": [
    "Notice:\n",
    "* Each YAML file must contain a dictionary key that returns a list of `create_table` \n",
    "objects. \n",
    "* Each object takes four table attributes: `name`, `num_rows`, `_metadata_`, and \n",
    "`columns`. \n",
    "* Each column is now represented by an object with the following format: `_target_: path.to.ColumnClass` \n",
    "* A node for instantiating YAML config files as objects using `hydra` is provided in `data_fabricator.v1.nodes.hydra.fabricate_datasets`. `hydra` is currently an optional dependency. To use this functionality you need to do `pip install brix.data_fabricator[hydra]`.\n",
    "Alternatively, if you prefer to use other object injection frameworks, you can utilize the clean node provided in data_fabricator.v1.nodes.fabrication.fabricate_datasets. Please note that in such cases, you may need to adjust the syntax accordingly to suit your chosen framework.\n",
    "* Each parameter of the respective class is passed directly below.\n",
    "* Arguments to the wrapper function `probability_null`, such as `prob_null`, `seed`, \n",
    "* and `null_value`, should go inside `prob_null_kwargs` argument as illustrated.\n",
    "* The function signature for `data_fabricator.v1.nodes.hydra.fabricate_datasets` is\n",
    " different from `data_fabricator.v0.nodes.fabrication.fabricate_datasets`.\n",
    "\n",
    "### Node Difference\n",
    "The function signature for the `v0` `fabricate_datasets`:\n",
    "\n",
    "```python\n",
    "def fabricate_datasets(\n",
    "    fabrication_params: Dict[str, Any],\n",
    "    ignore_prefix: List[str] = _IGNORE_DATAFRAMES_WITH_PREFIX,\n",
    "    seed: int = None,\n",
    "    **source_dfs: Dict[str, Union[pd.DataFrame, pyspark.sql.DataFrame]]\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "```\n",
    "\n",
    "The function signature for the `v1` `fabricate_datasets`:\n",
    "\n",
    "```python\n",
    "def fabricate_datasets(\n",
    "    ignore_prefix: List[str] = _IGNORE_DATAFRAMES_WITH_PREFIX,\n",
    "    seed: int = None,\n",
    "    **fabricator_params: Dict[str, List[BaseTable]]\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1446db6-10ef-4630-bf85-78a20d8d0c1f",
   "metadata": {},
   "source": [
    "Notice:\n",
    "* `fabricator_params` is now a dictionary of lists of `BaseTable` objects, which means\n",
    "   you can split your tables into different files. \n",
    "* `source_dfs` is now deprecated.\n",
    "\n",
    "## Available Data Fabricator Column Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d1ad1b-4c62-4caa-9b15-90dec0b39cde",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from data_fabricator.v1 import core\n",
    "import pkgutil\n",
    "import inspect\n",
    "import data_fabricator.v1.core.mock_generator\n",
    "from tabulate import tabulate\n",
    "from types import FunctionType\n",
    "\n",
    "\n",
    "pkgname = core.__name__\n",
    "pkgpath = core.__path__[0]\n",
    "found_packages = list(pkgutil.iter_modules([pkgpath], prefix=\"{}.\".format(pkgname)))\n",
    "sub_packages = [x.split(\".\")[-1] for _, x, _ in found_packages]\n",
    "\n",
    "importer = found_packages[0][0]\n",
    "\n",
    "func_row = []\n",
    "columns_row = []\n",
    "for idx, name in enumerate(sub_packages):\n",
    "    col_classes = []\n",
    "    list_of_functions = []\n",
    "    module_spec = importer.find_spec(found_packages[idx][1])\n",
    "    module = module_spec.loader.load_module(found_packages[idx][1])\n",
    "    clsmembers = inspect.getmembers(module, inspect.isclass)\n",
    "    col_classes.extend(\n",
    "        [\n",
    "            cls[1]\n",
    "            for cls in clsmembers\n",
    "            if (\n",
    "                issubclass(cls[1], data_fabricator.v1.core.mock_generator.BaseColumn)\n",
    "                and cls[1] != data_fabricator.v1.core.mock_generator.BaseColumn\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    func_members = inspect.getmembers(\n",
    "        data_fabricator.v1.core.functions, inspect.isfunction\n",
    "    )\n",
    "\n",
    "    for col in col_classes:\n",
    "        col_doc = col.__doc__.split(\"\\n\")[0]\n",
    "        columns_row.append(\n",
    "            {\"column class\": str(col).split(\"'\")[1], \"description\": col_doc}\n",
    "        )\n",
    "\n",
    "    if \"functions\" in module.__name__:\n",
    "        list_of_functions.extend(\n",
    "            [\n",
    "                (\".\".join([module.__name__, f[0]]), f[1])\n",
    "                for f in func_members\n",
    "                if isinstance(f[1], FunctionType)\n",
    "                and not f[0].startswith(\"_\")\n",
    "                and f[0]\n",
    "                not in [\n",
    "                    \"load_callable_with_libraries\",\n",
    "                    \"load_function_if_string\",\n",
    "                    \"probability_null\",\n",
    "                    \"wraps\",\n",
    "                    \"deepcopy\",\n",
    "                ]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for f in list_of_functions:\n",
    "            f_doc = f[1].__doc__.split(\"\\n\")[0]\n",
    "            func_row.append({\"function\": f[0], \"description\": f_doc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9036c526-7638-4e1d-9eb0-2bcb5f55b215",
   "metadata": {},
   "source": [
    "### Column Classes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3215a5f-50f5-44bf-801b-d29265be5116",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------------------------------------------------------+------------------------------------------------------------------------------+\n",
      "|    | column class                                                     | description                                                                  |\n",
      "|----+------------------------------------------------------------------+------------------------------------------------------------------------------|\n",
      "|  0 | data_fabricator.v1.core.mock_generator.ColumnApply               | Generic wrapper to call a function on a list.                                |\n",
      "|  1 | data_fabricator.v1.core.mock_generator.CrossProduct              | Given a list of lists, returns all possible combinations of values.          |\n",
      "|  2 | data_fabricator.v1.core.mock_generator.CrossProductWithSeparator | Given a list of lists, return possible combinations values.                  |\n",
      "|  3 | data_fabricator.v1.core.mock_generator.Date                      | Create an object that calls generate_dates and hold its attributes.          |\n",
      "|  4 | data_fabricator.v1.core.mock_generator.DropDuplicates            | Given a list of lists of all same length, return unique combinations.        |\n",
      "|  5 | data_fabricator.v1.core.mock_generator.Explode                   | Run a function for each row in ``list_of_values``.                           |\n",
      "|  6 | data_fabricator.v1.core.mock_generator.Faker                     | Thin wrapper for accessing Faker properties.                                 |\n",
      "|  7 | data_fabricator.v1.core.mock_generator.ForeignKey                | Convenience class for foreign-key type relationships.                        |\n",
      "|  8 | data_fabricator.v1.core.mock_generator.JoinedColumn              | Bring data from a column of another table based on key relationship.         |\n",
      "|  9 | data_fabricator.v1.core.mock_generator.NumpyRandom               | Create object that calls numpy_random and generate values in a distribution. |\n",
      "| 10 | data_fabricator.v1.core.mock_generator.PrimaryKey                | Thin wrapper for UniqueId to denote primary key.                             |\n",
      "| 11 | data_fabricator.v1.core.mock_generator.RandomArrays              | Generate random array with sample values.                                    |\n",
      "| 12 | data_fabricator.v1.core.mock_generator.RandomNumbers             | Generate random numbers between a specified range.                           |\n",
      "| 13 | data_fabricator.v1.core.mock_generator.RowApply                  | Create an object that call row_apply and hold its attributes.                |\n",
      "| 14 | data_fabricator.v1.core.mock_generator.UniqueId                  | Generate a list of unique integer ids with ``prefix`` prefix.                |\n",
      "| 15 | data_fabricator.v1.core.mock_generator.ValuesFromSamples         | Generate a list of values given sample values.                               |\n",
      "+----+------------------------------------------------------------------+------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "table = pd.DataFrame(columns_row)\n",
    "print(tabulate(table, headers=table.columns, tablefmt=\"psql\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6abb55-1103-4f2e-8422-dd91f6dbd9c4",
   "metadata": {},
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d441bc0e-fada-4ce8-ad92-b48e83f47d3c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------------------------------------------------+--------------------------------------------------------------------------+\n",
      "|    | function                                                            | description                                                              |\n",
      "|----+---------------------------------------------------------------------+--------------------------------------------------------------------------|\n",
      "|  0 | data_fabricator.v1.core.functions.column_apply                      | Generic wrapper to call a function on a list.                            |\n",
      "|  1 | data_fabricator.v1.core.functions.conditional_generate_from_weights | Generate a new distribution conditional on ``value``.                    |\n",
      "|  2 | data_fabricator.v1.core.functions.conditional_string                | Remap value based on the provided mapping.                               |\n",
      "|  3 | data_fabricator.v1.core.functions.cross_product                     | Given a list of lists, return all possible combinations values.          |\n",
      "|  4 | data_fabricator.v1.core.functions.cross_product_with_separator      | Given a list of lists, return possible combinations values.              |\n",
      "|  5 | data_fabricator.v1.core.functions.drop_duplicates                   | Given a list of lists of all same length, return unique combinations.    |\n",
      "|  6 | data_fabricator.v1.core.functions.explode                           | Run a function for each row in ``list_of_values``.                       |\n",
      "|  7 | data_fabricator.v1.core.functions.faker                             | Thin wrapper for accessing Faker properties.                             |\n",
      "|  8 | data_fabricator.v1.core.functions.generate_dates                    | Generate a range of dates.                                               |\n",
      "|  9 | data_fabricator.v1.core.functions.generate_random_arrays            | Generate random array with sample values.                                |\n",
      "| 10 | data_fabricator.v1.core.functions.generate_random_numbers           | Generate random numbers between a specified range, of type float or int. |\n",
      "| 11 | data_fabricator.v1.core.functions.generate_single_date              | Generate a single date.                                                  |\n",
      "| 12 | data_fabricator.v1.core.functions.generate_unique_id                | Generate a list of unique integer ids with ``prefix`` prefix.            |\n",
      "| 13 | data_fabricator.v1.core.functions.generate_values                   | Generate a list of values given sample values.                           |\n",
      "| 14 | data_fabricator.v1.core.functions.generate_values_from_weights      | Generate list of values for the provided weights.                        |\n",
      "| 15 | data_fabricator.v1.core.functions.hash_string                       | Hash a value to a given list of buckets.                                 |\n",
      "| 16 | data_fabricator.v1.core.functions.join_column                       | Generate the joined column based on the key relationship.                |\n",
      "| 17 | data_fabricator.v1.core.functions.numpy_random                      | Wrapper for numpy.random.                                                |\n",
      "| 18 | data_fabricator.v1.core.functions.row_apply                         | Generic wrapper to call a function for every element in a list.          |\n",
      "+----+---------------------------------------------------------------------+--------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "table = pd.DataFrame(func_row)\n",
    "print(tabulate(table, headers=table.columns, tablefmt=\"psql\"))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "qblabs-monorepo",
   "language": "python",
   "name": "qblabs-monorepo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
