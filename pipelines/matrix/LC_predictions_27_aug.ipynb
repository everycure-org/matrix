{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LC predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 27 Aug 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext kedro.ipython\n",
    "%reload_kedro  --env cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.append('matrix/matrix/src')\n",
    "from matrix.pipelines.modelling.model import ModelWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings - embeddings from 26 August run, setup 3. Downloaded from GCS\n",
    "EMB_PATH = '/Users/piotrkaniewski/work/run_infer/input/long_covid/rtx_kg2_nodes'\n",
    "emb_nodes = pd.read_parquet(EMB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID to embedding mapping \n",
    "id_to_embedding = {row['id']: row['topological_embedding'] for _, row in emb_nodes.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading usual RTX-KG 2.7.3 nodes dataset containing nodes names and ids (using Polars for speed)\n",
    "NODES_PATH  =  '/Users/piotrkaniewski/work/run_infer/input/rtx_kg2_nodes.tsv'\n",
    "nodes = pl.read_csv(NODES_PATH, separator='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model - xg_ensemble from 26 August run, setup 3.  Downloaded from MLFlow\n",
    "MODEL_PATH = '/Users/piotrkaniewski/work/run_infer/input/long_covid/ensemble_model.pkl'\n",
    "with open(MODEL_PATH, 'rb') as f:\n",
    "    model = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth positive dataset\n",
    "POS_PATH = '/Users/piotrkaniewski/work/run_infer/input/tp_pairs.txt'\n",
    "tp_df = pd.read_csv(POS_PATH, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for ranking drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_vectorised_dataset(df, id_to_embedding):\n",
    "    '''\n",
    "    Convert a drug-disease dataset into vectorised form.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe to convert. The drugs column is 'source' and disease column is 'target'.\n",
    "        id_to_embedding (dict): The dictionary to convert node ids to embeddings\n",
    "    Returns: \n",
    "        The vectorised dataset\n",
    "    '''\n",
    "    \n",
    "    vectorised_dataset = []\n",
    "    for _, row in df.iterrows():\n",
    "        drug_embedding = id_to_embedding[row['source']]\n",
    "        disease_embedding = id_to_embedding[row['target']]\n",
    "        vectorised_dataset.append(np.concatenate([drug_embedding, disease_embedding]))\n",
    "\n",
    "    return np.array(vectorised_dataset)\n",
    "\n",
    "    \n",
    "def get_probabilities(pairs, model, id_to_embedding):\n",
    "    \"\"\"\n",
    "    Get probability scores for drug-disease pairs dataset\n",
    "    \"\"\"\n",
    "    X = give_vectorised_dataset(pairs, id_to_embedding)\n",
    "    return model.predict_proba(X)\n",
    "\n",
    "\n",
    "def get_ranked_drugs(model, drugs_lst, disease_id, id_to_embedding):\n",
    "    \"\"\"\n",
    "    Gives sorted list of \"treat\" probability scores for a collection of drugs and a single disease\n",
    "    \"\"\"\n",
    "    pairs = pd.DataFrame({'source': drugs_lst,'target': disease_id})\n",
    "    pairs['treat_score'] = get_probabilities(pairs, model, id_to_embedding)[:,1]\n",
    "    pairs_sorted = pairs.sort_values('treat_score', ascending = False).reset_index(drop=True)\n",
    "    drugs_sorted = pairs_sorted.drop(columns='target')\n",
    "    drugs_sorted = drugs_sorted.rename(columns={'source': 'id'})\n",
    "    return drugs_sorted\n",
    "\n",
    "def add_names_to_list(preds : pd.DataFrame, nodes : pl.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add names and descriptions to the predictions list\n",
    "    \"\"\"\n",
    "    name_lst = [nodes.filter(pl.col('id') == drug_id)['name'].to_list()[0] for drug_id in preds['id']]\n",
    "    description_lst = [nodes.filter(pl.col('id') == drug_id)['des'].to_list()[0] for drug_id in preds['id']]\n",
    "    preds['name'] = name_lst\n",
    "    preds['description'] = description_lst\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the list of drugs, we use the set of drugs appearing in the ground truth positive dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_metadata =pd.read_parquet('data/03_primary/ec_medical_team/nodes')\n",
    "ec_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding long covid nodes\n",
    "covid_nodes = nodes.filter(pl.col('name').str.contains(r'(?i)covid'))\n",
    "print(covid_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOID definition of Long COVID\n",
    "LC_ID = 'DOID:0080848'\n",
    "\n",
    "# MONDO definition of Long COVID\n",
    "LC_MONDO_ID = 'MONDO:0100233'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of drugs and collection of nodes\n",
    "drugs_lst = list(tp_df['source'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for Long COVID DOID definition\n",
    "preds_doid = add_names_to_list(get_ranked_drugs(model, drugs_lst, LC_ID, id_to_embedding), nodes)\n",
    "preds_doid.to_csv('output_lc/predictions_LC_doid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for subtypes of Long COVID\n",
    "preds_subtypes_lst = [add_names_to_list(get_ranked_drugs(model, drugs_lst, 'EC:'+str(i+1), id_to_embedding), nodes) for i in range(9)]\n",
    "#preds_subtypes_lst = [preds_subtypes_lst[i].to_csv('output_lc/predictions_LC_subtype_'+str(i+1)+'.csv', index=False) for i in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_subtypes_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_df[tp_df.target==LC_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_df[tp_df.target==LC_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('long_covid_treat_scores.xlsx') as writer:  # doctest: +SKIP\n",
    "    ec_metadata.to_excel(writer, sheet_name='metadata')\n",
    "    for i in range(0,9):\n",
    "        preds_subtypes_lst[i].to_excel(writer, sheet_name=f'ec_{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the effect of adding extra edges, we can make predictions for the MONDO definition of Long COVID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction MONDO defintion of Long COVID\n",
    "preds_mondo = add_names_to_list(get_ranked_drugs(model, drugs_lst, LC_MONDO_ID, id_to_embedding), nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_subtypes_lst_500 = [lc_subtypes_df[i].head(500) for i in range(0,9)]\n",
    "for i in range(0,9):\n",
    "    preds_subtypes_lst_500[i]['subtype']=f'EC{i}'\n",
    "total_df = pd.concat(preds_subtypes_lst_500, axis=0)\n",
    "final_cumulative_df = total_df.loc[:,['id','name','description']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency across subtypes\n",
    "count_id = total_df.groupby(['id']).count()\n",
    "count_id['frequency'] = count_id.treat_score/9\n",
    "\n",
    "frequency_dict = count_id['frequency'].to_dict()\n",
    "final_cumulative_df['freq_across_subtypes_top500'] = final_cumulative_df['id'].map(frequency_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average across subtypes\n",
    "count_id['average'] = total_df.groupby(['id']).treat_score.mean()\n",
    "print(count_id)\n",
    "\n",
    "average_dict = count_id['average'].to_dict()\n",
    "final_cumulative_df['avg_score_across_subtypes_top500'] = final_cumulative_df['id'].map(average_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average across subtypes\n",
    "count_id['median'] = total_df.groupby(['id']).treat_score.median()\n",
    "print(count_id)\n",
    "\n",
    "median_dict = count_id['median'].to_dict()\n",
    "final_cumulative_df['median_score_across_subtypes_top500'] = final_cumulative_df['id'].map(median_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR \n",
    "def iqr(x):\n",
    "    return x.quantile(0.75) - x.quantile(0.25)\n",
    "\n",
    "count_id['iqr'] = total_df.groupby(['id']).treat_score.agg(iqr)\n",
    "\n",
    "iqr_dict = count_id['iqr'].to_dict()\n",
    "final_cumulative_df['iqr_score_across_subtypes_top500'] = final_cumulative_df['id'].map(iqr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dict = total_df.groupby(['id']).min().treat_score.to_dict()\n",
    "final_cumulative_df['min_score_across_subtypes_top500_score'] = final_cumulative_df['id'].map(min_dict)\n",
    "min_subtypes = {key: total_df.loc[((total_df.id==key)&(total_df.treat_score==value))].subtype.values[0] for key, value in min_dict.items()}\n",
    "final_cumulative_df['min_score_across_subtypes_top500_subtype'] = final_cumulative_df['id'].map(min_subtypes)\n",
    "\n",
    "max_dict = total_df.groupby(['id']).max().treat_score.to_dict()\n",
    "final_cumulative_df['max_score_across_subtypes_top500_score'] = final_cumulative_df['id'].map(max_dict)\n",
    "max_subtypes = {key: total_df.loc[((total_df.id==key)&(total_df.treat_score==value))].subtype.values[0] for key, value in max_dict.items()}\n",
    "final_cumulative_df['max_score_across_subtypes_top500_subtype'] = final_cumulative_df['id'].map(max_subtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mondo preds\n",
    "# preds_mondo = preds_mondo.sort_values('probs', ascending=False).loc[:,['id','name','description','probs']]\n",
    "# preds_mondo.rename(columns={'probs':'treat_score'})\n",
    "# preds_mondo.loc[:,['id','name','description','treat_score']].to_csv('output_lc/mondo_0100233.csv')\n",
    "\n",
    "# preds_mondo = preds_mondo.sort_values('probs', ascending=False).loc[:,['id','name','description','probs']]\n",
    "# preds_mondo.rename(columns={'probs':'treat_score'})\n",
    "# preds_mondo.loc[:,['id','name','description','treat_score']].to_csv('output_lc/mondo_0100233.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cumulative_df.to_csv('output_lc/cumulative_list_v1_wip_troubleshoot.csv') #working version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cumulative_df_copy = final_cumulative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('long_covid_treat_scores_v2.xlsx') as writer:  # doctest: +SKIP\n",
    "    preds_doid = preds_doid.sort_values('probs', ascending=False).loc[:,['id','name','description','probs']]\n",
    "    preds_doid.rename(columns={'probs':'treat_score'}).to_excel(writer, sheet_name='doid_0080848')\n",
    "    preds_mondo.loc[:,['id','name','description','treat_score']].to_csv('output_lc/mondo_0100233.csv')\n",
    "    preds_mondo = preds_mondo.sort_values('probs', ascending=False).loc[:,['id','name','description','probs']]\n",
    "    preds_mondo.rename(columns={'probs':'treat_score'}).to_excel(writer, sheet_name='mondo_0100233')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative format v2 (requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cumulative table if not in memory\n",
    "#final_cumulative_df.to_csv('output_lc/cumulative_list_v1_wip.csv') #working version\n",
    "\n",
    "#load all raw subtypes \n",
    "lc_subtypes_df = [pd.read_csv(f'output_lc/predictions_LC_subtype_{i}.csv') for i in range(1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list for all\n",
    "preds_subtypes_lst_all = lc_subtypes_df\n",
    "for i in range(0,9):\n",
    "    preds_subtypes_lst_all[i]['subtype']=f'EC{i}'\n",
    "total_df_all = pd.concat(preds_subtypes_lst_all, axis=0)\n",
    "final_cumulative_df_all = total_df_all.loc[:,['id','name','description']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency across subtypes all\n",
    "count_id = total_df_all.groupby(['id']).count()\n",
    "count_id['frequency'] = count_id.treat_score/9\n",
    "\n",
    "frequency_dict = count_id['frequency'].to_dict()\n",
    "final_cumulative_df_all['freq_across_subtypes_all'] = final_cumulative_df_all['id'].map(frequency_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average across subtypes\n",
    "count_id['average'] = total_df_all.groupby(['id']).treat_score.mean()\n",
    "print(count_id)\n",
    "\n",
    "average_dict = count_id['average'].to_dict()\n",
    "final_cumulative_df_all['avg_score_across_subtypes_all'] = final_cumulative_df_all['id'].map(average_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average across subtypes\n",
    "count_id['median'] = total_df_all.groupby(['id']).treat_score.median()\n",
    "print(count_id)\n",
    "\n",
    "average_dict = count_id['median'].to_dict()\n",
    "final_cumulative_df_all['median_score_across_subtypes_all'] = final_cumulative_df_all['id'].map(average_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR \n",
    "def iqr(x):\n",
    "    return x.quantile(0.75) - x.quantile(0.25)\n",
    "\n",
    "count_id['iqr'] = total_df_all.groupby(['id'])['treat_score'].agg(iqr)\n",
    "\n",
    "iqr_dict = count_id['iqr'].to_dict()\n",
    "final_cumulative_df_all['iqr_score_across_subtypes_all'] = final_cumulative_df_all['id'].map(iqr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dict = total_df_all.groupby(['id']).min().treat_score.to_dict()\n",
    "final_cumulative_df_all['min_score_across_subtypes_all_score'] = final_cumulative_df_all['id'].map(min_dict)\n",
    "min_subtypes = {key: total_df_all.loc[((total_df_all.id==key)&(total_df_all.treat_score==value))].subtype.values[0] for key, value in min_dict.items()}\n",
    "final_cumulative_df_all['min_score_across_subtypes_all_subtype'] = final_cumulative_df_all['id'].map(min_subtypes)\n",
    "\n",
    "max_dict = total_df_all.groupby(['id']).max().treat_score.to_dict()\n",
    "final_cumulative_df_all['max_score_across_subtypes_all_score'] = final_cumulative_df_all['id'].map(max_dict)\n",
    "max_subtypes = {key: total_df_all.loc[((total_df_all.id==key)&(total_df_all.treat_score==value))].subtype.values[0] for key, value in max_dict.items()}\n",
    "final_cumulative_df_all['max_score_across_subtypes_all_subtype'] = final_cumulative_df_all['id'].map(max_subtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in range(0,9):\n",
    "    name = f'EC{id}'\n",
    "    subtype_ids = total_df_all.loc[total_df_all.subtype==name].id.values\n",
    "    final_cumulative_df_all[f'in_{name}_top500'] = final_cumulative_df_all['id'].isin(subtype_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge cumulative v1 with v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure we have same indices\n",
    "final_cumulative_df_all = final_cumulative_df_all[final_cumulative_df_all.id.isin(final_cumulative_df.id)].reset_index()\n",
    "\n",
    "#merge\n",
    "final_cumulative_df_all = final_cumulative_df_all.merge(final_cumulative_df.drop(['name','description'], axis=1), on='id')\n",
    "\n",
    "#remove unwanted \n",
    "final_cumulative_df_all = final_cumulative_df_all.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cumulative_df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cumulative_df.to_csv('output_lc/cumulative_list_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cumulative_df_all.loc[:,['id', 'name', 'description', 'freq_across_subtypes_all',\n",
    "       'avg_score_across_subtypes_top500',\n",
    "       'avg_score_across_subtypes_all',\n",
    "       'median_score_across_subtypes_top500',\n",
    "       'median_score_across_subtypes_all',\n",
    "       'iqr_score_across_subtypes_top500',\n",
    "       'iqr_score_across_subtypes_all',\n",
    "       'min_score_across_subtypes_top500_score',\n",
    "       'min_score_across_subtypes_top500_subtype',\n",
    "       'max_score_across_subtypes_top500_score',\n",
    "       'max_score_across_subtypes_top500_subtype',\n",
    "       'min_score_across_subtypes_all_score',\n",
    "       'min_score_across_subtypes_all_subtype',\n",
    "       'max_score_across_subtypes_all_score',\n",
    "       'max_score_across_subtypes_all_subtype',\n",
    "       'in_EC0_top500', 'in_EC1_top500', 'in_EC2_top500', 'in_EC3_top500',\n",
    "       'in_EC4_top500', 'in_EC5_top500', 'in_EC6_top500', 'in_EC7_top500',\n",
    "       'in_EC8_top500']].to_csv('output_lc/final_cumulative_v3_fixed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treat score distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_doid['probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.hist(preds_doid['probs'].to_list()[0:100], bins=100, edgecolor='black', log=True)\n",
    "ax1.set_title('DOID Long COVID Predictions')\n",
    "ax1.set_xlabel('Probability')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_xlim(0, 1)\n",
    "\n",
    "ax2.hist(preds_mondo['probs'].to_list()[0:100], bins=100, edgecolor='black', log=True)\n",
    "ax2.set_title('MONDO Long COVID Predictions')\n",
    "ax2.set_xlabel('Probability')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_xlim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matrix-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
