run_comparison:

  # TODO: implement
  # matrix_harmonisation_mode: "strict" # "strict" or "lenient_on_ground_truth", "lenient_on_ground_truth_and_pairs"

  perform_multifold_uncertainty_estimation: True
  perform_bootstrap_uncertainty_estimation: True

  input_data:
    apply_harmonization: True
    input_paths:
      - name: good_model
        file_paths_list: 
          - ${globals:paths.raw}/run_comparison_matrices/matrix_fold_{1,2}_good_model.csv
        score_col_name: "treat score"
        file_format: "csv"
      - name: bad_model
        file_paths_list: 
          - ${globals:paths.raw}/run_comparison_matrices/matrix_fold_{1,2}_bad_model.csv
        score_col_name: "treat score"
        file_format: "csv"

  evaluations:
    ground_truth_recall_at_n:
      n_max: 22500
      N_bootstraps: 10
      num_n_values: 100
    negative_recall_at_n:
      n_max: 22500
      N_bootstraps: 10
      num_n_values: 100
    off_label_recall_at_n:
      n_max: 22500
      N_bootstraps: 10
      num_n_values: 100