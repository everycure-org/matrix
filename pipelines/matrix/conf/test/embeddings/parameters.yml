# https://platform.openai.com/docs/guides/embeddings/faq
# OpenAI embeddings support batching, up to 8000 tokens.
embeddings.node:
  batch_size: 1 # NOTE: The MockApi does not support batching, hence disabled
  input_features: ["category", "name"]
  encoder:
    object: matrix.pipelines.embeddings.encoders.RandomizedEncoder
    dimensions: 3

# Reducing dimensionality reduction to speed up runtime
embeddings.dimensionality_reduction:
  transformer:
    k: 2

embeddings.topological:
  estimator:
    args:
      batchSize: 20
      embeddingDimension: 3
