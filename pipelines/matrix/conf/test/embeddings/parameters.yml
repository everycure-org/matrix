# https://platform.openai.com/docs/guides/embeddings/faq
# OpenAI embeddings support batching, up to 8000 tokens.
embeddings.node:
  batch_size: 1 # NOTE: The MockApi does not support batching, hence disabled
  model:
    openai_api_base: ${oc.env:OPENAI_ENDPOINT}

# Reducing dimensionality reduction to speed up runtime
embeddings.dimensionality_reduction:
  transformer:
    k: 2

embeddings.topological:
  estimator:
    args:
      batchSize: 20
      embeddingDimension: 3
