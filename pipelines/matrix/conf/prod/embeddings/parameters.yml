# https://platform.openai.com/docs/guides/embeddings/faq
# OpenAI embeddings support batching, up to 8000 tokens.
embeddings.ai_config:
  batch_size: 1500
  concurrency: 50

# Defines strategy used to reduce dimensions of the GenAI
# generated node embeddings.
# https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.PCA.html
embeddings.dimensionality_reduction:
  transformer:
    object: pyspark.ml.feature.PCA
    k: 100

embeddings.topological:
  estimator:
    model: graphSage
    args:
      # Chunyu: 512
      embeddingDimension: 512
      # Chunyu: 200k
      batchSize: 20000
      epochs: 10
      searchDepth: 100
      # Chunyu
      # learningRate: 0.01
      learningRate: 0.1
