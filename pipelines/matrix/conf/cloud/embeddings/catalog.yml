_bigquery_ds: &_bigquery_ds
  type: matrix.datasets.gcp.BigQueryTableDataset
  project_id: ${oc.env:GCP_PROJECT_ID}
  dataset: runs
  identifier: "${globals:run_name}"
  file_format: parquet
  save_args:
    bigQueryTableLabel.git_sha: ${globals:git_sha}
    temporaryGcsBucket: ${globals:gcs_bucket}

embeddings.feat.nodes:
  <<: *_bigquery_ds
  table: nodes
  filepath: ${globals:paths.feat}/nodes

embeddings.feat.edges:
  <<: *_bigquery_ds
  table: "edges"
  filepath: ${globals:paths.feat}/edges

embeddings.reporting.loss:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  artifact_path: topological
  dataset:
    # NOTE: Data needs to be stored locally for MLFlow
    # to be able to upload to GCS. The ML Tracking server
    # is setup to not serve artifacts, thereby interacting
    # directly with GCS as a result.
    type: kedro_datasets.matplotlib.MatplotlibWriter
    filepath: ${globals:paths.tmp}/convergence_plot.png

embeddings.reporting.topological_pca_plot:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  artifact_path: topological
  dataset:
    # NOTE: Data needs to be stored locally for MLFlow
    # to be able to upload to GCS. The ML Tracking server
    # is setup to not serve artifacts, thereby interacting
    # directly with GCS as a result.
    type: kedro_datasets.matplotlib.MatplotlibWriter
    filepath: ${globals:paths.tmp}/pca_plot.png