# Name of column representing main probability score of the model 
# Column name for main probability score
# Aggregations to report in MLFlow (list of names in modelling.aggregation_functions)
evaluation.reported_aggregations:
  - mean
  - amin
  - amax

# Threshold-based classification metrics for ground truth data
evaluation.simple_classification:
  evaluation_options:
    generator:
      _object: matrix.datasets.pair_generator.GroundTruthTestPairs
      positive_columns: 
        - "is_known_positive"
      negative_columns:
        - "is_known_negative"
    evaluation:
      _object: matrix.pipelines.evaluation.evaluation.DiscreteMetrics 
      metrics:
        - _object: sklearn.metrics.accuracy_score
        - _object: sklearn.metrics.f1_score
      threshold: 0.5

# Disease-specific ranking
evaluation.disease_specific:
  evaluation_options:
    generator:
      _object: matrix.datasets.pair_generator.MatrixTestDiseases
      positive_columns: 
        - "is_known_positive"
      removal_columns:
        - "trial_sig_better"
        - "trial_non_sig_better"
    evaluation:
      _object: matrix.pipelines.evaluation.evaluation.SpecificRanking 
      specific_col: "target"
      rank_func_lst: 
        - _object: matrix.pipelines.evaluation.named_metric_functions.MRR
        - _object:  matrix.pipelines.evaluation.named_metric_functions.HitK
          k: 2
        - _object:  matrix.pipelines.evaluation.named_metric_functions.HitK
          k: 10
        - _object:  matrix.pipelines.evaluation.named_metric_functions.HitK
          k: 100

# Full matrix ranking 
evaluation.full_matrix:
  evaluation_options:
    generator:
      _object: matrix.datasets.pair_generator.FullMatrixPositives
      positive_columns: 
        - "is_known_positive"
      removal_columns:
        - "trial_sig_better"
        - "trial_non_sig_better"
    evaluation:
      _object: matrix.pipelines.evaluation.evaluation.FullMatrixRanking 
      rank_func_lst: 
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN 
          n: 1000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN
          n: 10000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN
          n: 100000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN
          n: 1000000
      quantile_func_lst: 
        - _object: matrix.pipelines.evaluation.named_metric_functions.AUROC

# Full matrix ranking for known negatives against unknowns
evaluation.full_matrix_negatives:
  evaluation_options:
    generator:
      _object: matrix.datasets.pair_generator.FullMatrixPositives
      positive_columns: 
        - "is_known_negative"
      removal_columns:
        - "trial_sig_worse"
        - "trial_non_sig_worse"
    evaluation:
      _object: matrix.pipelines.evaluation.evaluation.FullMatrixRanking 
      rank_func_lst: 
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN
          n: 10000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN
          n: 100000
      quantile_func_lst: 
        - _object: matrix.pipelines.evaluation.named_metric_functions.AUROC

          

## Clinical trial versions. These use ground truth provided by results of clinical trials occurring after March 2023 (release date of RTX-KG2 v2.7.3).

# Threshold-based classification metrics for ground truth data (clinical trials version)
evaluation.simple_classification_trials:
  evaluation_options:
    generator:
      _object: matrix.datasets.pair_generator.GroundTruthTestPairs
      positive_columns: 
        - "trial_sig_better"
        - "trial_non_sig_better"
      negative_columns:
        - "trial_sig_worse"
        - "trial_non_sig_worse"
    evaluation:
      _object: matrix.pipelines.evaluation.evaluation.DiscreteMetrics
      metrics:
        - _object: sklearn.metrics.accuracy_score
        - _object: sklearn.metrics.f1_score
      threshold: 0.5

# Disease-specific ranking (clinical trials version)
evaluation.disease_specific_trials:
  evaluation_options:
    generator:
      _object: matrix.datasets.pair_generator.MatrixTestDiseases
      positive_columns: 
        - "trial_sig_better"
        - "trial_non_sig_better"
      removal_columns: 
        - "is_known_positive"
    evaluation:
      _object: matrix.pipelines.evaluation.evaluation.SpecificRanking
      specific_col: "target"
      rank_func_lst: 
        - _object: matrix.pipelines.evaluation.named_metric_functions.MRR
        - _object:  matrix.pipelines.evaluation.named_metric_functions.HitK
          k: 2
        - _object:  matrix.pipelines.evaluation.named_metric_functions.HitK
          k: 10
        - _object:  matrix.pipelines.evaluation.named_metric_functions.HitK
          k: 100

# Full matrix ranking (clinical trials version)
evaluation.full_matrix_trials:
  evaluation_options:
    generator:
      _object: matrix.datasets.pair_generator.FullMatrixPositives
      positive_columns:
        - "trial_sig_better"
        - "trial_non_sig_better"
      removal_columns:
        - "is_known_positive"
    evaluation:
      _object: matrix.pipelines.evaluation.evaluation.FullMatrixRanking 
      rank_func_lst: 
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN 
          n: 1000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN
          n: 10000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN
          n: 100000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN
          n: 1000000
      quantile_func_lst: 
        - _object: matrix.pipelines.evaluation.named_metric_functions.AUROC

## Off Label Datasets evaluation

# Disease-specific ranking (off-label version)
evaluation.disease_specific_off_label:
  evaluation_options:
    generator:
      _object: matrix.datasets.pair_generator.MatrixTestDiseases
      positive_columns: 
        - "off_label"
    evaluation:
      _object: matrix.pipelines.evaluation.evaluation.SpecificRanking
      specific_col: "target"
      rank_func_lst: 
        - _object: matrix.pipelines.evaluation.named_metric_functions.MRR
        - _object:  matrix.pipelines.evaluation.named_metric_functions.HitK
          k: 2
        - _object:  matrix.pipelines.evaluation.named_metric_functions.HitK
          k: 10
        - _object:  matrix.pipelines.evaluation.named_metric_functions.HitK
          k: 100

# Off label rankings
evaluation.full_matrix_off_label:
  evaluation_options:
    generator:
      _object: matrix.datasets.pair_generator.FullMatrixPositives
      positive_columns:
        - "off_label"
    evaluation:
      _object: matrix.pipelines.evaluation.evaluation.FullMatrixRanking 
      rank_func_lst: 
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN 
          n: 1000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN
          n: 10000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN
          n: 100000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.RecallAtN
          n: 1000000
      quantile_func_lst: 
        - _object: matrix.pipelines.evaluation.named_metric_functions.AUROC

evaluation.stability_overlap:
  evaluation_options:
    generator:
      _object: matrix.datasets.pair_generator.NoGenerator
    stability:
      _object: matrix.pipelines.evaluation.evaluation.StabilityCommonalityAtN
      rank_func_lst: 
        - _object:  matrix.pipelines.evaluation.named_metric_functions.CommonalityAtN
          n: 10000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.CommonalityAtN
          n: 1000000

evaluation.stability_ranking:
   evaluation_options:
    generator:
      _object: matrix.datasets.pair_generator.OnlyOverlappingPairs
    stability:
      _object: matrix.pipelines.evaluation.evaluation.StabilityRankingMetrics 
      rank_func_lst: 
        - _object:  matrix.pipelines.evaluation.named_metric_functions.SpearmanAtN
          n: 10000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.SpearmanAtN
          n: 1000000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.HypergeomAtN
          n: 10000
        - _object:  matrix.pipelines.evaluation.named_metric_functions.HypergeomAtN
          n: 1000000