_spark_parquet_ds: &_spark_parquet
  type: matrix_gcp_datasets.gcp.LazySparkDataset
  file_format: parquet
  load_args:
    header: True
  save_args:
    mode: overwrite

_pandas_parquet: &_pandas_parquet
  type: matrix.datasets.graph.PandasParquetDataset
  save_args:
    engine: pyarrow
  load_args:
    engine: pyarrow

_layer_int: &_layer_int
  metadata:
    kedro-viz:
      layer: integration

_layer_prm: &_layer_prm
  metadata:
    kedro-viz:
      layer: primary

# -------------------------------------------------------------------------
# Datasets
# -------------------------------------------------------------------------

integration.int.{source}.nodes:
  <<: [*_spark_parquet, *_layer_int]
  filepath: ${globals:paths.integration}/int/{source}/nodes

integration.int.{source}.edges:
  <<: [*_spark_parquet, *_layer_int]
  filepath: ${globals:paths.integration}/int/{source}/edges

# Normalized KGs
integration.int.{source}.nodes.norm@spark:
  <<: [*_spark_parquet, *_layer_int]
  filepath: ${globals:paths.integration}/int/{source}/nodes.norm

integration.int.{source}.nodes.norm@pandas:
  <<: [*_pandas_parquet, *_layer_int]
  filepath: ${globals:paths.integration}/int/{source}/nodes.norm

integration.int.{source}.edges.norm@spark:
  <<: [*_spark_parquet, *_layer_int]
  filepath: ${globals:paths.integration}/int/{source}/edges.norm

integration.int.{source}.edges.norm@pandas:
  <<: [*_pandas_parquet, *_layer_int]
  filepath: ${globals:paths.integration}/int/{source}/edges.norm

# mapping tables 
integration.int.{source}.nodes_norm_mapping:
  <<: [*_spark_parquet, *_layer_int]
  filepath: ${globals:paths.integration}/int/{source}/nodes_norm_mapping

integration.int.core_node_mapping:
  <<: [*_spark_parquet, *_layer_int]
  filepath: ${globals:paths.integration}/int/core_norm_mapping


# Unified KGs
integration.prm.unified_nodes:
  <<: [*_spark_parquet, *_layer_prm]
  filepath: ${globals:paths.integration}/prm/unified/nodes

integration.prm.unified_edges:
  <<: [*_spark_parquet, *_layer_prm]
  filepath: ${globals:paths.integration}/prm/unified/edges

integration.int.unified_ground_truth_edges:
  <<: [*_spark_parquet, *_layer_prm]
  filepath: ${globals:paths.integration}/int/ground_truth/edges.norm

integration.prm.nodes_edges_consistency_check:
  type: text.TextDataset
  filepath: ${globals:paths.integration}/prm/nodes_edges_consistency_check.txt
# ==============================
# Original sources: only used for sampling

# The create_sample pipeline needs to pull data from the release, but write data in the sample environment
# We need to define another entry in the base catalog, otherwise the sample environment integration.prm.unified_nodes will reference itself

integration.prm.original.unified_nodes:
  <<: [*_spark_parquet]
  filepath: ${globals:paths.integration}/prm/unified/nodes

integration.prm.original.unified_edges:
  <<: [*_spark_parquet]
  filepath: ${globals:paths.integration}/prm/unified/edges

# Normalization summary tables
integration.int.{source}.normalization_summary:
  <<: [*_spark_parquet, *_layer_int]
  filepath: ${globals:paths.integration}/int/{source}/normalization_summary

integration.prm.unified_normalization_summary:
  <<: [*_spark_parquet, *_layer_prm]
  filepath: ${globals:paths.integration}/prm/unified_normalization_summary

# Metrics
integration.prm.metric_abox_tbox:
  <<: [*_spark_parquet, *_layer_int]
  filepath: ${globals:paths.integration}/prm/metric_abox_tbox