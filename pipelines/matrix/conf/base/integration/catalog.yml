_spark_parquet_ds: &_spark_parquet
  type: matrix.datasets.gcp.LazySparkDataset
  file_format: parquet
  load_args:
    header: True
  save_args:
    mode: overwrite

_pandas_parquet: &_pandas_parquet
  type: pandas.ParquetDataset

_layer_int: &_layer_int
  metadata:
    kedro-viz:
      layer: integration
_layer_prm: &_layer_prm
  metadata:
    kedro-viz:
      layer: primary

# -------------------------------------------------------------------------
# Datasets
# -------------------------------------------------------------------------


# NOTE: We're plugging into the live source as we expect this to change rather,
# moreover, we consider it highly unlikely that paths would suddently change
# across biolink versions.
integration:
  raw.biolink.predicates:
    type: kedro_datasets.json.JSONDataset
    filepath: https://biolink.github.io/biolink-model/predicates.json

  raw.biolink.categories:
    type: kedro_datasets.json.JSONDataset
    filepath: https://biolink.github.io/biolink-model/categories.json

  int.{source}.nodes:
    <<: [*_spark_parquet, *_layer_int]
    filepath: ${globals:paths.integration}/int/{source}/nodes

  int.{source}.edges:
    <<: [*_spark_parquet, *_layer_int]
    filepath: ${globals:paths.integration}/int/{source}/edges

  # Normalized KGs
  int.{source}.nodes.norm:
    <<: [*_spark_parquet, *_layer_int]
    filepath: ${globals:paths.integration}/int/{source}/nodes.norm

  int.{source}.edges.norm:
    <<: [*_spark_parquet, *_layer_int]
    filepath: ${globals:paths.integration}/int/{source}/edges.norm

  # mapping tables 
  int.{source}.nodes_norm_mapping:
    <<: [*_spark_parquet, *_layer_int]
    filepath: ${globals:paths.integration}/int/{source}/nodes_norm_mapping

  # Unified KGs
  prm.unified_edges:
    <<: [*_spark_parquet, *_layer_prm]
    filepath: ${globals:paths.integration}/prm/unified/edges

  prm.unified_nodes:
    <<: [*_spark_parquet, *_layer_prm]
    filepath: ${globals:paths.integration}/prm/unified/nodes

  # filtered KGs
  prm.filtered_edges:
    <<: [*_spark_parquet, *_layer_prm]
    filepath: ${globals:paths.integration}/prm/filtered/edges

  # FUTURE more elegant: Apply all node filters, then all edge filters, then a "cleanup" final step that removes
  # 1. all edges where nodes were deleted
  # 2. all nodes that have not one edge connected anymore
  prm.prefiltered_nodes:
    <<: [*_spark_parquet, *_layer_prm]
    filepath: ${globals:paths.integration}/prm/prefiltered/nodes

  prm.filtered_nodes:
    <<: [*_spark_parquet, *_layer_prm]
    filepath: ${globals:paths.integration}/prm/filtered/nodes


  int.ec_medical_team.nodes:
    <<: [*_spark_parquet, *_layer_int]
    filepath: ${globals:paths.integration}/int/ec_medical_team/nodes

  int.ec_medical_team.edges:
    <<: [*_spark_parquet, *_layer_int]
    filepath: ${globals:paths.integration}/int/ec_medical_team/edges
