_pandas_csv: &_pandas_csv
  type:  pandas.CSVDataset

_pandas_parquet: &_pandas_parquet
  type: pandas.ParquetDataset

_spark_csv_ds: &_spark_csv
  type: spark.SparkDataset
  file_format: csv
  load_args:
    header: true
    sep: ","

_spark_parquet_ds: &_spark_parquet
  type: spark.SparkDataset
  file_format: parquet
  save_args:
    mode: overwrite

_neo4j_ds: &_neo4j_ds
  type: matrix.datasets.neo4j.Neo4JSparkDataset
  database: everycure
  url: ${oc.env:NEO4J_HOST}
  credentials: neo4j_credentials
  save_args:
    mode: "overwrite"
  
integration.raw.rtx_kg2.nodes@pandas:
  <<: *_pandas_csv
  filepath: ${globals:paths.raw}/rtx_kg2_nodes.csv
  
integration.raw.rtx_kg2.nodes@spark:
  <<: *_spark_csv
  filepath: ${globals:paths.raw}/rtx_kg2_nodes.csv

integration.raw.rtx_kg2.edges@pandas:
  <<: *_pandas_csv
  filepath: ${globals:paths.raw}/rtx_kg2_edges.csv

integration.raw.rtx_kg2.edges@spark:
  <<: *_spark_csv
  filepath: ${globals:paths.raw}/rtx_kg2_edges.csv

integration.raw.ground_truth.positives:
  <<: *_pandas_csv
  filepath: ${globals:paths.raw}/tp_pairs.txt

integration.raw.ground_truth.negatives:
  <<: *_pandas_csv
  filepath: ${globals:paths.raw}/tn_pairs.txt

integration.int.known_pairs@pandas:
  <<: *_pandas_parquet
  filepath: ${globals:paths.int}/ground_truth

integration.int.known_pairs@spark:
  <<: *_spark_parquet
  filepath: ${globals:paths.int}/ground_truth

integration.prm.rtx_kg2.nodes:
  <<: *_spark_parquet
  filepath: ${globals:paths.prm}/rtx_kg2/nodes

integration.prm.rtx_kg2.edges:
  <<: *_spark_parquet
  filepath: ${globals:paths.prm}/rtx_kg2/edges

# FUTURE: Does it make sense to copy DBs?
integration.model_input.nodes:
  <<: *_neo4j_ds
  save_args:
    # NOTE: Neo4j nodes can have multiple labels. We're adding _all_ nodes in a global
    # `entity` label on which we generate a unique constraint. This has the side-effect
    # that an index is created which allows for quick edge inserts down the line.
    # https://neo4j.com/docs/cypher-manual/current/constraints/
    script: >
      CREATE CONSTRAINT IF NOT EXISTS FOR (n:Entity) REQUIRE n.id IS UNIQUE;
    query: > 
      CREATE (n:Entity {id: event.id})
      WITH event, n
      CALL apoc.create.addLabels(n, [event.label]) YIELD node
      CALL apoc.create.setProperties(n, event.property_keys, event.property_values) YIELD node AS n2
      RETURN node
  load_args:
    # NOTE: The 'biolink' prefixes was removed to have a clean Neo4J UI interface. We're adding
    # it back into the query as the modelling expects it.
    query: >  
      MATCH (n) RETURN n.id AS id, 'biolink:' + labels(n)[0] AS category 
 

integration.model_input.edges:
  <<: *_neo4j_ds
  save_args:
    # NOTE: The `match:Entity` ensures that the index we created above is leveraged
    # while inserting edges, thereby speeding up the process massively.
    query: > 
      MATCH (subject:Entity {id: event.subject}), (object:Entity {id: event.object})
      WITH subject, object, event
      CALL apoc.create.relationship(subject, event.label, {knowledge_source: event.knowledge_source}, object) YIELD rel
      RETURN rel

integration.model_input.ground_truth:
  <<: *_neo4j_ds
  save_args:
    query: > 
      MATCH (source:Entity {id: event.source_id}), (target:Entity {id: event.target_id})
      WITH source, target, event
      CALL
        apoc.do.when(
          not exists((source)-[:GROUND_TRUTH]->(target)), 
          'CREATE (source)-[rel:GROUND_TRUTH]->(target) RETURN rel',
          'MATCH (source)-[rel:GROUND_TRUTH]->(target) return rel',
          {event:event, source:source, target:target}
        ) YIELD value
      CALL apoc.create.setRelProperties(value.rel, event.property_keys, event.property_values) YIELD rel as r
      RETURN count(*)
  load_args:        
    query: >
      MATCH (drug:Drug)-[r:GROUND_TRUTH]->(disease:Disease) 
      RETURN 
        drug.id as source, 
        drug.topological_embedding as source_embedding,
        disease.id as target, 
        disease.topological_embedding as target_embedding,
        toInteger(r.treats) as y