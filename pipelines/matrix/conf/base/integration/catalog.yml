_spark_csv_ds: &_spark_csv
  type: spark.SparkDataset
  file_format: csv
  load_args:
    header: true
    sep: ","

_neo4j_ds: &_neo4j_ds
  type: matrix.datasets.neo4j.Neo4JSparkDataset
  database: everycure # TODO: Can also add version number here, but local does not support
  url: bolt://127.0.0.1:7687
  credentials: neo4j_credentials
  save_args:
    mode: "overwrite"
  
integration.raw.rtx_kg2.nodes:
  <<: *_spark_csv
  filepath: ${globals:paths.raw}/rtx_kg2_nodes.csv

integration.raw.rtx_kg2.edges:
  <<: *_spark_csv
  filepath: ${globals:paths.raw}/rtx_kg2_edges.csv

integration.prm.drugs:
  <<: *_neo4j_ds
  metadata:
    labels: ":Drug"
    node.keys: id

integration.prm.diseases:
  <<: *_neo4j_ds
  metadata:
    labels: ":Disease"
    node.keys: id

# TODO: Verify if we can align with Biolink
integration.prm.treats:
  <<: *_neo4j_ds
  metadata:
    relationship: TREATS
    relationship.save.strategy: keys
    relationship.source.save.mode: overwrite
    relationship.source.labels: ":Drug"
    relationship.source.node.keys: source_id:id
    relationship.target.save.mode: overwrite
    relationship.target.labels: ":Disease"
    relationship.target.node.keys: target_id:id

integration.prm.pypher:
  <<: *_neo4j_ds


# TODO: BigQuery does not work locally, what is our approach here?
# do we use local SparkDatasets for local iteration, and only have the BigQuery
# datasets in prod? This will impact test coverage. Alternatively there is the 
# bigquery emulator, but it seems like connecting to it from the Spark connector  
# is not supported :(
_bigquery_ds: &_bigquery_ds
  type: matrix.datasets.gcp.BigQueryTableDataset
  project_id: mtrx-hub-dev-3of
  dataset: kg

# We can use partitioning to isolate different versions. Though it seems BigQuery
# only detects them when they use a date-ish formatting, as opposed to
# a number as mentioned by the docs.
# https://cloud.google.com/bigquery/docs/partitioned-tables#dt_partition_shard
# https://stackoverflow.com/questions/70194094/how-to-create-sharded-table-in-gcp-bigquery
integration.raw.bigquery.edges:
  <<: *_bigquery_ds
  table: "edges_${globals:versions.kg}"