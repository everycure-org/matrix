preprocessing:
  rtx:
    exclude_labels:
      - InformationResource
      - Device
      - GraphicaLocation
    semmed_filters:
      publication_threshold: 10
      ngd_threshold: 0.6

integration:
  nodenorm:
    # api_endpoint: https://nodenormalization-sri.renci.org/get_normalized_nodes
    api_endpoint: ${oc.env:NODENORM_ENDPOINT, https://nodenorm.transltr.io/1.5/get_normalized_nodes}
    conflate: true
    drug_chemical_conflate: true
    batch_size: 1000
    parallelism: 120

  unification:
    datasets_to_union:
      - rtx
      - medical_team
      - robokop # TODO comment out until we have managed to scale the downstream pipeline to 150M edges and 25M nodes

  filtering:
    node_filters:
      filter_node_labels:
        object: matrix.pipelines.modelling.utils.partial_
        func:
          object: matrix.pipelines.integration.filters.remove_rows_containing_category
        column: category
        categories:
        # TODO: We should likely not remove these before our data release stage but afterwards in the modelling pipeline (if the model so desires)
          - biolink:Activity
          - biolink:Agent
          - biolink:ClinicalIntervention
          - biolink:Cohort
          - biolink:Device
          - biolink:EnvironmentalFeature
          - biolink:EnvironmentalProcess
          - biolink:Event
          - biolink:GeographicLocation
          - biolink:IndividualOrganism
          - biolink:InformationContentEntity
          - biolink:InformationResource
          - biolink:LifeStage
          - biolink:MaterialSample
          - biolink:NamedThing
          - biolink:Phenomenon
          - biolink:PhysicalEntity
          - biolink:PopulationOfIndividualOrganisms
          - biolink:Procedure
          - biolink:Publication
          - biolink:Treatment
    edge_filters:
      filter_biolink_edges:
        object: matrix.pipelines.modelling.utils.partial_
        func:
          object: matrix.pipelines.integration.filters.biolink_deduplicate