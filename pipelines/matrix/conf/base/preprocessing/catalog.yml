_layer_raw: &_layer_raw
  metadata:
    kedro-viz:
      layer: raw

_layer_int: &_layer_int
  metadata:
    kedro-viz:
      layer: integration

_layer_prm: &_layer_prm
  metadata:
    kedro-viz:
      layer: primary

_pandas_csv: &_pandas_csv
  type:  pandas.CSVDataset

_spark_csv_ds: &_spark_csv
  type: spark.SparkDataset
  file_format: csv
  load_args:
    header: true
    sep: ","
  save_args:
    mode: overwrite
    header: true

_bigquery_ds: &_bigquery_ds
  type: matrix.datasets.gcp.BigQueryTableDataset
  project_id: ${oc.env:GCP_PROJECT_ID}

# -------------------------------------------------------------------------
# Datasets
# -------------------------------------------------------------------------

preprocessing.raw.nodes:
  <<: *_layer_raw
  type: pandas.ExcelDataset
  filepath: ${globals:paths.raw}/exp.xlsx
  load_args:
    sheet_name: Nodes

preprocessing.raw.edges:
  <<: *_layer_raw
  type: pandas.ExcelDataset
  filepath: ${globals:paths.raw}/exp.xlsx
  load_args:
    sheet_name: Edges

preprocessing.int.resolved_nodes:
  <<: [*_layer_int]
  type: pandas.ExcelDataset
  filepath: ${globals:paths.int}/medical/resolved_nodes.xlsx
  save_args:
    sheet_name: Nodes

preprocessing.int.normalized_nodes:
  <<: [*_layer_int]
  type: pandas.ExcelDataset
  filepath: ${globals:paths.int}/medical/normalized_nodes.xlsx
  save_args:
    sheet_name: Nodes

preprocessing.int.nodes@pandas:
  <<: *_pandas_csv
  filepath: ${globals:paths.int}/medical/nodes.csv

preprocessing.int.nodes@spark:
  <<: *_spark_csv
  filepath: ${globals:paths.int}/medical/nodes.csv

# preprocessing.prm.nodes:
#   <<: [*_layer_prm, *_spark_csv]
#   filepath: ${globals:paths.prm}/exp/nodes

# NOTE: Writing to BigQuery to have handover point
preprocessing.prm.nodes:
  <<: [*_layer_prm, *_bigquery_ds]
  dataset: kg_medical
  table: nodes
  identifier: "${globals:data_sources.medical.version}"
  save_args:
    temporaryGcsBucket: ${globals:gcs_bucket}
    bigQueryTableLabel.kg: medical

preprocessing.int.edges@pandas:
  <<: [*_layer_int, *_pandas_csv]
  filepath: ${globals:paths.int}/exp/edges.csv

preprocessing.int.edges@spark:
  <<: [*_layer_int, *_spark_csv]
  filepath: ${globals:paths.int}/exp/edges.csv

# preprocessing.prm.edges:
#   <<: [*_layer_prm, *_spark_csv]
#   filepath: ${globals:paths.prm}/exp/edges

# NOTE: Writing to BigQuery to have handover point
preprocessing.prm.edges:
  <<: [*_layer_prm, *_bigquery_ds]
  dataset: kg_medical
  table: edges
  identifier: "${globals:data_sources.medical.version}"
  save_args:
    temporaryGcsBucket: ${globals:gcs_bucket}
    bigQueryTableLabel.kg: medical