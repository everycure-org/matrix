_spark_parquet_ds: &_spark_parquet
  type: matrix.datasets.gcp.LazySparkDataset
  file_format: parquet
  save_args:
    mode: overwrite

_pandas_parquet: &_pandas_parquet
  type: pandas.ParquetDataset

_kg_dataset: &_kg_dataset
  type: matrix.datasets.graph.KnowledgeGraphDataset
  load_args:
    engine: pyarrow
    use_nullable_dtypes: True

_layer_raw: &_layer_raw
  metadata:
    kedro-viz:
      layer: raw

_layer_int: &_layer_int
  metadata:
    kedro-viz:
      layer: integration

modelling.raw.ground_truth.positives:
  <<: [*_pandas_csv, *_layer_raw]
  filepath: ${globals:paths.raw}/ground_truth_data/tp_pairs.txt
  load_args:
    sep: "\t"
  save_args: 
    sep: "\t"

modelling.raw.ground_truth.negatives:
  <<: [*_pandas_csv, *_layer_raw]
  filepath: ${globals:paths.raw}/ground_truth_data/tn_pairs.txt
  load_args:
    sep: "\t"
  save_args: 
    sep: "\t"

modelling.int.known_pairs:
  <<: [*_pandas_parquet, *_layer_int]
  filepath: ${globals:paths.int}/ground_truth

# filtered down further to drugs/diseases
modelling.model_input.drugs_diseases_nodes@spark:
  <<: *_spark_parquet
  filepath: ${globals:paths.model_input}/drugs_diseases_nodes/

# commented out until https://github.com/fsspec/gcsfs/issues/632 is fixed
# modelling.model_input.drugs_diseases_nodes@pandas:
#   <<: *_pandas_parquet
#   filepath: ${globals:paths.model_input}/drugs_diseases_nodes/

modelling.feat.rtx_kg2:
  <<: *_kg_dataset
  filepath: ${globals:paths.feat}/rtx_kg2_nodes

modelling.model_input.splits:
  <<: *_pandas_parquet
  filepath: ${globals:paths.model_input}/splits

"modelling.{model}.model_input.transformers":
  type: pickle.PickleDataset
  filepath: ${globals:paths.model_input}/{model}/transformers.pickle

"modelling.{model}.model_input.transformed_splits":
  <<: *_pandas_parquet
  filepath: ${globals:paths.model_input}/{model}/transformed_splits

"modelling.{model}.{shard}.model_input.enriched_splits":
  <<: *_pandas_parquet
  filepath: ${globals:paths.model_input}/{model}/{shard}/enriched_splits

"modelling.{model}.{shard}.model_input.transformed_splits":
  <<: *_pandas_parquet
  filepath: ${globals:paths.model_input}/{model}/{shard}/transformed_splits

"modelling.{model}.{shard}.models.model_params":
  type: yaml.YAMLDataset
  filepath: ${globals:paths.models}/{model}/{shard}/model_params.yml

"modelling.{model}.{shard}.models.model":
  type: pickle.PickleDataset
  filepath: ${globals:paths.models}/{model}/{shard}/model.pickle

"modelling.{model}.model_output.predictions":
  <<: *_pandas_parquet
  filepath: ${globals:paths.model_output}/{model}/predictions

# NOTE: Saving an artifact, saving both locally and in MLFlow
# https://kedro-mlflow.readthedocs.io/en/stable/source/04_experimentation_tracking/03_version_datasets.html#how-to-version-data-in-a-kedro-project
"modelling.{model}.{shard}.reporting.tuning_convergence_plot":
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  artifact_path: "{model}/{shard}"
  dataset:
    type: matplotlib.MatplotlibWriter
    filepath: ${globals:paths.tmp}/{model}/{shard}/convergence_plot.png

# NOTE: Tracking a model, other serialization formats possible.
# https://kedro-mlflow.readthedocs.io/en/stable/source/04_experimentation_tracking/04_version_models.html#how-to-track-models-using-mlflow-in-kedro-project
"modelling.{model}.models.model":
  type: kedro_mlflow.io.models.MlflowModelTrackingDataset
  flavor: mlflow.sklearn
  pyfunc_workflow: python_model
  artifact_path: "{model}"

# NOTE: Saving a metric, more elaborate strategies possible, e.g., MlflowMetricHistoryDataset
# https://kedro-mlflow.readthedocs.io/en/stable/source/04_experimentation_tracking/05_version_metrics.html#saving-a-single-float-as-a-metric-with-mlflowmetricdataset
"modelling.{model}.reporting.metrics":
  type: matrix.datasets.mlflow.MlflowMetricsDataset
  key_prefix: "{model}"