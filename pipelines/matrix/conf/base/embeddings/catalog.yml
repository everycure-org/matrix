_neo4j_ds: &_neo4j_ds
  type: matrix.datasets.neo4j.Neo4JSparkDataset
  database: everycure-${globals:versions.release}
  url: ${globals:neo4j.host}
  credentials: neo4j_credentials
  save_args:
    mode: "overwrite"

_spark_parquet_ds: &_spark_parquet
  type: matrix.datasets.gcp.LazySparkDataset
  file_format: parquet
  save_args:
    mode: overwrite

# Catalog directly expresses a query to add OpenAI embeddings.
# https://neo4j.com/labs/apoc/5/installation/
# https://neo4j.com/labs/apoc/5/ml/vertexai/#_generate_embeddings_api
embeddings.prm.graph.embeddings@yaml:
  type: yaml.YAMLDataset
  filepath: ${globals:paths.prm}/embeddings/result.yml

embeddings.prm.graph.embeddings@neo:
  <<: *_neo4j_ds
  load_args:
    # NOTE: Using the `query` reader option highly impacts performance, hence resorting to `labels`.
    # https://neo4j.com/docs/spark/current/read/options/
    partitions: 16 # Should increase parallelism for PCA
    labels: ":Entity" #avoids query which drastically increases performance
    # query: >
    #   MATCH (n: Entity) RETURN n.id as id, n.embedding as embedding

embeddings.prm.graph.pca_embeddings:
  <<: *_neo4j_ds
  save_args:
    query: > 
      MATCH (n:Entity {id: event.id})
      WITH event, n
      CALL apoc.create.setProperty(n, "pca_embedding", event.pca_embedding) YIELD node
      RETURN node
  load_args:
    query: >
      MATCH (n: Entity) 
      RETURN n.id as id, n.pca_embedding as embedding

embeddings.feat.include_in_graphsage@yaml:
  filepath: ${globals:paths.feat}/graphsage_filter/result.yml
  type:  yaml.YAMLDataset

embeddings.models.graphsage:
  # we do not actually do anything with this DS, thus it's a dummy
  # https://github.com/kedro-org/kedro/discussions/3758
  filepath: ${globals:paths.prm}/graphsage/result.yml
  type:  yaml.YAMLDataset

# NOTE: Dummy catalog entry to enforce Kedro dependency
# between embedding and modelling pipeline.
embeddings.model_output.graphsage:
  <<: *_neo4j_ds
  save_args:
    # Dummy Query that never gets written to because we use GDS to execute the write-back of graphsage
    persist: false
  load_args:
    # NOTE: Using the `query` reader option highly impacts performance, hence resorting to `labels`.
    # https://neo4j.com/docs/spark/current/read/options/
    partitions: 16 # Should increase parallelism
    labels: ":Entity" # avoids query which drastically increases performance

embeddings.feat.nodes:
  <<: *_spark_parquet
  filepath: ${globals:paths.feat}/nodes
      

embeddings.reporting.loss:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  artifact_path: "topological"
  dataset:
    type: matplotlib.MatplotlibWriter
    filepath: ${globals:paths.tmp}/topological/convergence_plot.png


embeddings.feat.edges:
  <<: *_spark_parquet
  filepath: ${globals:paths.feat}/edges
