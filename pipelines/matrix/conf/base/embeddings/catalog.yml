_neo4j_ds: &_neo4j_ds
  type: matrix.datasets.neo4j.Neo4JSparkDataset
  database: everycure-${globals:versions.release}
  url: ${oc.env:NEO4J_HOST}
  credentials: neo4j_credentials
  save_args:
    mode: "overwrite"

_spark_parquet_ds: &_spark_parquet
  type: spark.SparkDataset
  versioned: true
  file_format: parquet
  save_args:
    mode: overwrite


embeddings.prm.graph.embeddings:
  <<: *_spark_parquet
  filepath: ${globals:paths.feat}/embeddings

embeddings.prm.graph.pca_embeddings:
  <<: *_neo4j_ds
  save_args:
    query: > 
      MATCH (n:Entity {id: event.id})
      WITH event, n
      CALL apoc.create.setProperty(n, "pca_embedding", event.pca_embedding) YIELD node
      RETURN node
  load_args:
    query: >
      MATCH (n: Entity) 
      RETURN n.id as id, n.pca_embedding as embedding

embeddings.models.graphsage:
  versioned: true
  # we do not actually do anything with this DS, thus it's a dummy
  # https://github.com/kedro-org/kedro/discussions/3758
  filepath: ${globals:paths.prm}/graphsage/result.yml
  type:  yaml.YAMLDataset

# NOTE: Dummy catalog entry to enforce Kedro dependency
# between embedding and modelling pipeline.
embeddings.model_output.graphsage:
  <<: *_neo4j_ds
  save_args:
    # Dummy Query that never gets written to because we use GDS to execute the write-back of graphsage
    persist: false
  load_args:
    query: >
      MATCH (n: Entity) 
      RETURN 
          n.id as id, 
          n.name as name,
          n.category as category,
          n.description as description,
          n.topological_embedding as topological_embedding

embeddings.feat.nodes:
  <<: *_spark_parquet
  filepath: ${globals:paths.feat}/nodes
      
embeddings.feat.edges:
  <<: *_spark_parquet
  filepath: ${globals:paths.feat}/edges
