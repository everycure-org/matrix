# Neo4J graph database configuration. Used to orchestrate
# queries into Neo4j.
embeddings.gdb:
  object: matrix.pipelines.embeddings.nodes.GraphDB
  endpoint: ${globals:neo4j.host}
  database: analytics
  auth:
    -  ${globals:neo4j.user}
    -  ${globals:neo4j.password}

embeddings.node:
  batch_size: 500
  features: ["category", "name"]
  model:
    object: langchain_openai.OpenAIEmbeddings
    model: text-embedding-3-small
    openai_api_key: ${oc.env:OPENAI_API_KEY}
    dimensions: 100
    timeout: 10

# Defines strategy used to reduce dimensions of the GenAI
# generated node embeddings.
# https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.PCA.html
embeddings.dimensionality_reduction:
  skip: true # NOTE: Currently skipping PCA as performed by OpenAI directly
  input: embedding
  output: &_pca_property 'pca_embedding'
  transformer:
    object: pyspark.ml.feature.PCA
    k: 100

# FUTURE: This is a highly temp. solution that serves as PoC of leveraging Neo4J's
# AI functionality. If works as expected, we'll do a refinement step to clean this up.
embeddings.gds:
  object: matrix.pipelines.embeddings.nodes.GraphDS
  endpoint: ${globals:neo4j.host}
  database: analytics
  auth:
    -  ${globals:neo4j.user}
    -  ${globals:neo4j.password}

# Defines strategy used to compute topological embeddings,
# all nodes and relationships in our KG are projected, along with
# the PCA feature. The graphSage algorithm is hereafter applied
# and the result is written back to the KG.
# 
# Sources:
#   - https://neo4j.com/docs/graph-data-science/current/management-ops/graph-creation/graph-project/
#   - https://neo4j.com/docs/graph-data-science-client/current/graph-object/
#   - https://neo4j.com/docs/graph-data-science-client/current/model-object/
#   - https://neo4j.com/docs/graph-data-science-client/current/algorithms/ 
# 
embeddings.topological:
  # Configuration to perform Neo4J graph
  # projection into GDS library for algorithm
  # execution.
  projection:
    graphName: embeddings
    nodeProjection:
      Entity:
        label: 'Entity'
        properties: *_pca_property
    relationshipProjection: '*'
    configuration:
      relationshipProperties: 
        include_in_graphsage:
          property: include_in_graphsage
          defaultValue: 1
  
  # Configuration to apply filtering on projected GDS 
  # graph, ensuring various edges are removed
  # prior to model training.
  filtering:
    graphName: filtered_embeddings 
    args:
      node_filter: '*'
      relationship_filter: r.include_in_graphsage = 1.0
  
  # Name of the model in Neo4j
  estimator:
    modelName: topological_embeddings
  
  write_property: &_topological_property 'topological_embedding'

# uncomment for node2vec
embeddings.topological_estimator:
  object: matrix.pipelines.embeddings.graph_algorithms.GDSNode2Vec 
  concurrency: 4
  embedding_dim: 512
  random_seed: 42
  iterations: 10
  in_out_factor: 1
  return_factor: 1
  initial_learning_rate: 0.025
  min_learning_rate: 0.000025
  negative_sampling_rate: 5
  walk_length: 30
  walks_per_node: 10
  window_size: 100

# embeddings.topological_estimator:
#   object: matrix.pipelines.embeddings.graph_algorithms.GDSGraphSage
#   concurrency: 4
#   iterations: 100
#   sample_sizes: [25, 10]
#   tolerance: 1e-8
#   embedding_dim: 512
#   batch_size: 5000
#   epochs: 10
#   search_depth: 100
#   learning_rate: 0.01
#   activation_function: ReLu
#   random_seed: 42
#   feature_properties: [*_pca_property]
#   # negative_sampling_weight: 20

embeddings.write_topological_col: *_topological_property

embeddings.topological_pca:
  skip: false # Set to true to skip PCA
  input: *_topological_property
  output: 'pca_embedding'
  transformer:
    object: pyspark.ml.feature.PCA
    k: 2
