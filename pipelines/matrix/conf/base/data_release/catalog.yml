_neo4j_ds: &_neo4j_ds
  type: matrix.datasets.neo4j.Neo4JSparkDataset
  database: everycure-${globals:versions.release}
  url: ${globals:neo4j.host}
  credentials: neo4j_credentials
  save_args:
    mode: "overwrite"

_spark_parquet_ds: &_spark_parquet
  type: matrix_gcp_datasets.gcp.LazySparkDataset
  file_format: parquet
  save_args:
    mode: overwrite
  metadata:
    kedro-viz:
      layer: embeddings

_spark_kgx_ds: &_spark_kgx_ds
  type: matrix_gcp_datasets.gcp.LazySparkDataset
  file_format: csv
  save_args:
    mode: overwrite
    sep: '\t'
    header: True

data_release.prm.kg_nodes:
  <<: *_neo4j_ds
  save_args:
    mode: overwrite
    script: >
      CREATE CONSTRAINT IF NOT EXISTS FOR (n:Entity) REQUIRE n.id IS UNIQUE;
    query: > 
      CREATE (n:Entity {id: event.id, kg_sources: event.kg_sources})
      WITH event, n
      CALL apoc.create.addLabels(n, [event.label]) YIELD node
      CALL apoc.create.setProperties(n, event.property_keys, event.property_values) YIELD node AS n2
      CALL apoc.create.setProperties(n, event.array_property_keys, event.array_property_values) YIELD node AS n3
      RETURN node

data_release.prm.kg_edges:
  <<: [*_neo4j_ds]
  save_args:
    # NOTE: The `match:Entity` ensures that the index we created above is leveraged
    # while inserting edges, thereby speeding up the process massively.
    query: > 
      MATCH (subject:Entity {id: event.subject}), (object:Entity {id: event.object})
      WITH subject, object, event
      CALL apoc.create.relationship(subject, event.label, {kg_sources: event.upstream_data_source, primary_knowledge_source: event.primary_knowledge_source}, object) YIELD rel
      RETURN rel

# This entity belongs to commented out option of data_release pipeline.
# data_release.prm.kg_embeddings:
#   <<: [*_neo4j_ds]
#   save_args:
#     # NOTE: The `match:Entity` ensures that the index we created above is leveraged
#     # while inserting edges, thereby speeding up the process massively.
#     query: > 
#       MATCH (n:Entity {id: event.id})
#       WITH n, event
#       CALL apoc.create.setProperties(n, ['topological_embedding'], [event.topological_embedding]) YIELD node
#       RETURN node

data_release.feat.nodes_with_embeddings:
  <<: *_spark_parquet
  filepath: ${globals:paths.release}/prm/nodes_with_embeddings

data_release.prm.bigquery_edges:
  <<: *_spark_parquet
  filepath: ${globals:paths.release}/prm/bigquery_edges

data_release.prm.bigquery_nodes:
  <<: *_spark_parquet
  filepath: ${globals:paths.release}/prm/bigquery_nodes

data_release.prm.kgx_nodes:
  <<: *_spark_kgx_ds
  filepath: ${globals:paths.release}/kgx/nodes.tsv

data_release.prm.kgx_edges:
  <<: *_spark_kgx_ds
  filepath: ${globals:paths.release}/kgx/edges.tsv

data_release.dummy:
  type: yaml.YAMLDataset
  filepath: ${globals:paths.tmp}/foo.yaml
