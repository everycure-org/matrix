spark.sql.execution.arrow.pyspark.enabled: true
spark.scheduler.mode: FAIR
spark.driver.memory: ${oc.env:SPARK_DRIVER_MEMORY}g
# only using this due to 
# https://github.com/fsspec/gcsfs/issues/632
spark.driver.maxResultSize: 18g
# only using this due to failures in the past. Default is 3
spark.task.maxFailures: 5

# FUTURE: Use Maven based dependency when fixed
# https://github.com/GoogleCloudDataproc/hadoop-connectors/issues/1233#issuecomment-2262873434
spark.jars: gcs-connector-hadoop3-2.2.2-shaded.jar
spark.jars.packages: com.google.cloud.spark:spark-3.5-bigquery:0.39.0,org.neo4j:neo4j-connector-apache-spark_2.12:5.3.0_for_spark_3,org.xerial:sqlite-jdbc:3.47.0.0
spark.hadoop.fs.gs.impl: com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem
spark.hadoop.fs.gs.auth.type: UNAUTHENTICATED