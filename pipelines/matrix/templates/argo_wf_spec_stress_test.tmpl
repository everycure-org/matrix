apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  namespace: {{namespace}}
  name: {{run_name}}
spec:
  workflowMetadata:
    labels:
      run: {% raw %}'{{ workflow.parameters.run_name }}'
      {% endraw %}
      username: "{{ username }}"
      test_type: "gpu_stress_test"
      gpu_type: "nvidia-l4"
  entrypoint: "gpu-stress-test"
  arguments:
    parameters:
      - name: run_name
        value: "{{ run_name }}"
      - name: num_gpus
        value: "1"
      - name: memory_limit
        value: "8"
      - name: memory_request
        value: "4"
      - name: cpu_limit
        value: "2"
      - name: cpu_request
        value: "1"
  templates:
  - name: gpu-stress-test
    metrics:
      prometheus:
        - name: "argo_gpu_stress_test_duration_seconds"
          help: "Duration of GPU stress test"
          labels:
            - key: test_type
              value: "gpu_stress_test"
            - key: gpu_type
              value: "nvidia-l4"
          histogram:
            buckets: [60, 120, 180, 240, 300, 360]
            value: {% raw %}"{{workflow.duration}}"
            {% endraw %}
        - name: "argo_gpu_stress_test_completion"
          help: "GPU stress test completion status"
          labels:
            - key: test_type
              value: "gpu_stress_test"
            - key: status
              value: {% raw %}"{{status}}"
              {% endraw %}
          counter:
            value: "1"
    inputs:
      parameters:
      - name: num_gpus
      - name: memory_limit
      - name: memory_request
      - name: cpu_limit
      - name: cpu_request
    metadata:
      labels:
        app: kedro-argo  # Changed to match Prometheus service monitor
        test_type: gpu-stress-test
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9400"
        prometheus.io/path: "/metrics"
        prometheus.io/scheme: "http"
    container:
      image: oguzpastirmaci/gpu-burn:latest
      imagePullPolicy: Always
      env:
        - name: NVIDIA_VISIBLE_DEVICES
          value: "all"
        - name: NVIDIA_DRIVER_CAPABILITIES
          value: "compute,utility"
        - name: RUN_NAME
          value: {% raw %} "{{workflow.parameters.run_name}}" 
          {% endraw %}
    # Pod specification with GPU resources
    podSpecPatch: |
      tolerations:
        - key: "node-memory-size"
          operator: "Equal"
          value: "large"
          effect: "NoSchedule"
      containers:
        - name: main
          resources:
            requests:
              memory: {% raw %} "{{inputs.parameters.memory_request}}Gi"
              {% endraw %}
              cpu: {% raw %} "{{inputs.parameters.cpu_request}}"
              {% endraw %}
              nvidia.com/gpu: 1
            limits:
              memory: {% raw %} "{{inputs.parameters.memory_limit}}Gi"
              {% endraw %}
              cpu: {% raw %} "{{inputs.parameters.cpu_limit}}"
              {% endraw %}
              nvidia.com/gpu: 1
    # Volumes for GPU access
    volumes:
      - name: nvidia-install-dir-host
        hostPath:
          path: /home/kubernetes/bin/nvidia
          type: DirectoryOrCreate
      - name: pod-resources
        hostPath:
          path: /var/lib/kubelet/pod-resources
          type: DirectoryOrCreate
    # Node affinity and tolerations
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: cloud.google.com/gke-accelerator
              operator: Exists
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          preference:
            matchExpressions:
            - key: accelerator
              operator: In
              values:
              - nvidia-tesla-l4
              - nvidia-l4
        - weight: 90
          preference:
            matchExpressions:
            - key: gpu_node
              operator: In
              values:
              - "true"
        - weight: 80
          preference:
            matchExpressions:
            - key: node.kubernetes.io/instance-type
              operator: In
              values:
              - g2-standard-4
              - g2-standard-8
              - g2-standard-12
              - g2-standard-16
        - weight: 60
          preference:
            matchExpressions:
            - key: cloud.google.com/gke-accelerator
              operator: Exists
    tolerations:
    - key: "node-memory-size"
      operator: "Equal"
      value: "large"
      effect: "NoSchedule"
    - key: "nvidia.com/gpu"
      operator: "Exists"
      effect: "NoSchedule"
    - key: "cloud.google.com/gke-accelerator"
      operator: "Exists"
      effect: "NoSchedule"
    - key: "ToBeDeletedByClusterAutoscaler"
      operator: "Exists"
      effect: "NoSchedule"
    - key: "node.kubernetes.io/not-ready"
      operator: "Exists"
      effect: "NoExecute"
      tolerationSeconds: 300
    - key: "node.kubernetes.io/unreachable"
      operator: "Exists"
      effect: "NoExecute"
      tolerationSeconds: 300
