{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Analysis Notebook\n",
    "\n",
    "This notebook provides a template for analyzing embeddings using the Embedding Projector. It includes functions for loading and caching embeddings and labels, as well as a dashboard app for visualizing embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use This Notebook\n",
    "\n",
    "1. Run the cells in the \"Setup\" section to import necessary libraries and functions.\n",
    "2. Modify the variables in the \"Configuration\" section to specify the dataset and embedding files.\n",
    "3. Run the cells in the \"Load Data\" section to load the embeddings and labels.\n",
    "4. Run the cells in the \"Visualize Embeddings\" section to launch the dashboard app.\n",
    "\n",
    "Note: The dataset caching functionality is handled by the functions imported from `embedding_utils.py`. You can modify variables to change how embeddings work and specify different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pandas as pd\n",
    "import openai\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from kedro.framework.project import configure_project\n",
    "from kedro.framework.session import KedroSession\n",
    "\n",
    "utils_path = os.path.abspath('/home/wadmin/embed_norm/apps/embed_norm/embed_norm_test')\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "root_path = subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode().strip()\n",
    "os.chdir(Path(root_path) / 'pipelines' / 'matrix')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from embedding_utils import (\n",
    "    process_model,\n",
    "    embedding_models_info,\n",
    "    parse_list_string,\n",
    "    load_datasets,\n",
    "    load_embeddings_and_labels,\n",
    "    missing_data_rows_dict,\n",
    "    generate_candidate_pairs,\n",
    "    refine_candidate_mappings_with_llm,\n",
    "    find_additional_mappings_with_curategpt\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Variables\n",
    "\n",
    "Specify your dataset names, seeds, and cache directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = os.path.join(root_path, 'apps', 'embed_norm', 'cached_datasets')\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "for subdir in ['categories', 'embeddings', 'datasets']:\n",
    "    os.makedirs(os.path.join(cache_dir, subdir), exist_ok=True)\n",
    "\n",
    "pos_seed = 54321\n",
    "neg_seed = 67890\n",
    "\n",
    "dataset_name = 'rtx_kg2.int'\n",
    "nodes_dataset_name = 'integration.int.rtx.nodes'\n",
    "edges_dataset_name = 'integration.int.rtx.edges'\n",
    "\n",
    "categories = ['All Categories']\n",
    "\n",
    "model_name = 'OpenAI'\n",
    "model_info = embedding_models_info[model_name]\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "total_sample_size = 1000\n",
    "positive_ratio = 0.2\n",
    "\n",
    "positive_n = int(total_sample_size * positive_ratio)\n",
    "negative_n = total_sample_size - positive_n\n",
    "cache_suffix = f\"_pos_{positive_n}_neg_{negative_n}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets and Embeddings\n",
    "\n",
    "Use the provided functions to load datasets and embeddings, handling caching automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_project('matrix')\n",
    "\n",
    "with KedroSession.create() as session:\n",
    "    context = session.load_context()\n",
    "    catalog = context.catalog\n",
    "    nodes_df = catalog.load(nodes_dataset_name)\n",
    "\n",
    "categories, positive_datasets, datasets = load_datasets(\n",
    "    nodes_df=nodes_df,\n",
    "    cache_dir=os.path.join(cache_dir, 'datasets'),\n",
    "    dataset_name=dataset_name,\n",
    "    seed1=pos_seed,\n",
    "    seed2=neg_seed,\n",
    "    total_sample_size=total_sample_size,\n",
    "    positive_ratio=positive_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Text Representation and Label Generation Functions\n",
    "\n",
    "Customize how embeddings are generated by defining custom text representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def node_to_string(row, text_fields=None):\n",
    "#     if text_fields is None:\n",
    "#         text_fields = ['all_names:string[]', 'all_categories:string[]']\n",
    "#     global missing_data_rows_dict\n",
    "#     fields = [row.get(field, '') for field in text_fields]\n",
    "#     missing_fields = [field for field, value in zip(text_fields, fields)\n",
    "#                       if pd.isnull(value) or not str(value).strip()]\n",
    "#     for missing_field in missing_fields:\n",
    "#         if missing_field not in missing_data_rows_dict:\n",
    "#             missing_data_rows_dict[missing_field] = []\n",
    "#         missing_data_rows_dict[missing_field].append(row)\n",
    "#     text_values = []\n",
    "#     for field_value in fields:\n",
    "#         parsed_list = parse_list_string(field_value)\n",
    "#         text_values.extend(parsed_list)\n",
    "#     text_representation = ' '.join(text_values).strip()\n",
    "#     if not text_representation:\n",
    "#         logging.warning(f\"Empty text representation for row with index {row.name}\")\n",
    "#     return text_representation\n",
    "\n",
    "\n",
    "def node_to_string(row, text_fields):\n",
    "    fields = [row.get(field, '') for field in text_fields]\n",
    "    text_values = []\n",
    "    for field_value in fields:\n",
    "        if pd.notnull(field_value):\n",
    "            parsed_list = parse_list_string(field_value)\n",
    "            text_values.extend(parsed_list)\n",
    "    return ' '.join(text_values).strip()\n",
    "\n",
    "def label_func(row):\n",
    "    return f\"{row['id']}, {row['name']}, custom label\"\n",
    "\n",
    "text_fields = ['name', 'description', 'category', 'labels', 'all_categories', 'equivalent_identifiers']\n",
    "\n",
    "print(nodes_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Models\n",
    "\n",
    "Generate and cache embeddings for your datasets using the `process_model` functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate or Load Embeddings for Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, embeddings_dict = process_model(\n",
    "    model_name=model_name,\n",
    "    model_info=model_info,\n",
    "    datasets=datasets,\n",
    "    cache_dir=os.path.join(cache_dir, 'embeddings'),\n",
    "    seed=neg_seed,\n",
    "    text_fields=text_fields,\n",
    "    text_representation_func=node_to_string,\n",
    "    # label_generation_func=label_func,\n",
    "    dataset_name=dataset_name,\n",
    "    use_ontogpt=False,\n",
    "    cache_suffix=cache_suffix\n",
    ")\n",
    "\n",
    "model_name, embeddings_dict_pos = process_model(\n",
    "    model_name=model_name,\n",
    "    model_info=model_info,\n",
    "    datasets=positive_datasets,\n",
    "    cache_dir=os.path.join(cache_dir, 'embeddings'),\n",
    "    seed=pos_seed,\n",
    "    text_fields=text_fields,\n",
    "    text_representation_func=node_to_string,\n",
    "    # label_generation_func=label_func,\n",
    "    dataset_name=dataset_name,\n",
    "    use_ontogpt=False,\n",
    "    cache_suffix=cache_suffix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "category = 'All Categories'\n",
    "embeddings = embeddings_dict[category]\n",
    "# Assuming labels_dict is loaded or generated accordingly\n",
    "# labels = labels_dict[category]\n",
    "\n",
    "reduced_embeddings = PCA(n_components=2).fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], alpha=0.5)\n",
    "plt.title(f'Embeddings Visualization for {category}')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
