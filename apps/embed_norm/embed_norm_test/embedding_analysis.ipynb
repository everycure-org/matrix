{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Embedding Analysis Notebook\n",
    "\n",
    "This notebook provides a template for analyzing embeddings using the Embedding Projector. It includes functions for loading and caching embeddings and labels, as well as a dashboard app for visualizing embeddings.\n",
    "\n",
    "## How to Use This Notebook\n",
    "\n",
    "1. Run the cells in the \"Setup\" section to import necessary libraries and functions.\n",
    "2. Modify the variables in the \"Configuration\" section to specify the dataset and embedding files.\n",
    "3. Run the cells in the \"Load Data\" section to load the embeddings and labels.\n",
    "4. Run the cells in the \"Visualize Embeddings\" section to launch the dashboard app.\n",
    "\n",
    "\n",
    "Note: The dataset caching functionality is handled by the functions imported from `embedding_utils.py`. You can modify variables to change how embeddings work and specify different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pandas as pd\n",
    "import openai\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from kedro.framework.project import configure_project\n",
    "\n",
    "# Add the path to the utils\n",
    "utils_path = os.path.abspath('/home/wadmin/embed_norm/apps/embed_norm/embed_norm_test')\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "root_path = subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode().strip()\n",
    "os.chdir(Path(root_path) / 'pipelines' / 'matrix')\n",
    "\n",
    "from embedding_utils import (\n",
    "    process_model,\n",
    "    # process_model_combinations,\n",
    "    embedding_models_info,\n",
    "    parse_list_string,\n",
    "    load_datasets,\n",
    "    load_categories,\n",
    "    load_embeddings_and_labels,\n",
    "    missing_data_rows_dict,\n",
    "    generate_candidate_pairs,\n",
    "    refine_candidate_mappings_with_llm,\n",
    "    find_additional_mappings_with_curategpt\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Set Up Variables\n",
    "\n",
    "Specify your dataset names, seeds, and cache directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up variables\n",
    "cache_dir = root_path + '/apps/embed_norm/cached_datasets'\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "# Seeds for sampling\n",
    "seed1 = 54321  # Seed for positive samples\n",
    "seed2 = 67890  # Seed for negative samples\n",
    "\n",
    "# Dataset configuration\n",
    "# dataset_name = 'rtx_kg2'  # Replace with your dataset name integration.int.rtx.\n",
    "# nodes_dataset_name = 'ingestion.raw.rtx_kg2.nodes@pandas'  # Replace with your nodes dataset name\n",
    "# edges_dataset_name = 'ingestion.raw.rtx_kg2.edges@pandas'  # Replace with your edges dataset name\n",
    "\n",
    "dataset_name = 'rtx_kg2'\n",
    "nodes_dataset_name = 'integration.int.rtx.nodes'\n",
    "edges_dataset_name = 'integration.int.rtx.edges'\n",
    "\n",
    "# Categories to process\n",
    "categories = ['All Categories']  # Specify categories or use 'All Categories'\n",
    "\n",
    "# Model configuration\n",
    "model_name = 'OpenAI'\n",
    "model_info = embedding_models_info[model_name]\n",
    "\n",
    "# OpenAI API Key (if using OpenAI embeddings)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Ensure your API key is set\n",
    "\n",
    "# New adjustable sample size and ratio\n",
    "total_sample_size = 1000  # Total number of samples\n",
    "positive_ratio = 0.2     # Ratio of positive samples\n",
    "\n",
    "# Cache suffix based on sample size and ratio\n",
    "positive_n = int(total_sample_size * positive_ratio)\n",
    "negative_n = total_sample_size - positive_n\n",
    "cache_suffix = f\"_pos_{positive_n}_neg_{negative_n}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Load Datasets and Embeddings\n",
    "\n",
    "Use the provided functions to load datasets and embeddings, handling caching automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Kedro project\n",
    "configure_project('matrix')\n",
    "\n",
    "# Load categories\n",
    "categories = load_categories(\n",
    "    cache_dir=f'{cache_dir}/categories',\n",
    "    dataset_name=dataset_name,\n",
    "    nodes_dataset_name=nodes_dataset_name\n",
    ")\n",
    "\n",
    "# Load datasets\n",
    "positive_datasets, datasets = load_datasets(\n",
    "    cache_dir=f'{cache_dir}/datasets',\n",
    "    dataset_name=dataset_name,\n",
    "    nodes_dataset_name=nodes_dataset_name,\n",
    "    edges_dataset_name=edges_dataset_name,\n",
    "    categories=categories,\n",
    "    seed1=seed1,\n",
    "    seed2=seed2,\n",
    "    total_sample_size=total_sample_size,\n",
    "    positive_ratio=positive_ratio\n",
    ")\n",
    "\n",
    "# # Load embeddings and labels (if cached)\n",
    "# embeddings_dict, labels_dict = load_embeddings_and_labels(\n",
    "#     cache_dir=f'{cache_dir}/embeddings',\n",
    "#     dataset_name=dataset_name,\n",
    "#     model_name=model_name,\n",
    "#     categories=categories,\n",
    "#     seed=seed2,\n",
    "#     combinations=False,\n",
    "#     cache_suffix=cache_suffix\n",
    "# )\n",
    "\n",
    "# # Similarly for positive datasets\n",
    "# embeddings_dict_pos, labels_dict_pos = load_embeddings_and_labels(\n",
    "#     cache_dir=f'{cache_dir}/embeddings',\n",
    "#     dataset_name=dataset_name,\n",
    "#     model_name=model_name,\n",
    "#     categories=categories,\n",
    "#     seed=seed1,\n",
    "#     combinations=False,\n",
    "#     cache_suffix=cache_suffix\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Define Text Representation and Label Generation Functions\n",
    "\n",
    "Customize how embeddings are generated by defining custom text representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom text representation function\n",
    "# def node_to_string(row):\n",
    "#     fields = [row.get('name', ''), row.get('description', '')]\n",
    "#     text_values = []\n",
    "#     for field_value in fields:\n",
    "#         if pd.notnull(field_value):\n",
    "#             parsed_list = parse_list_string(field_value)\n",
    "#             text_values.extend(parsed_list)\n",
    "#     return ' '.join(text_values).strip()\n",
    "\n",
    "def node_to_string(row, text_fields=None):\n",
    "    if text_fields is None:\n",
    "        text_fields = ['all_names:string[]', 'all_categories:string[]']\n",
    "    global missing_data_rows_dict\n",
    "    fields = [row.get(field, '') for field in text_fields]\n",
    "    missing_fields = [field for field, value in zip(text_fields, fields)\n",
    "                      if pd.isnull(value) or not str(value).strip()]\n",
    "    for missing_field in missing_fields:\n",
    "        if missing_field not in missing_data_rows_dict:\n",
    "            missing_data_rows_dict[missing_field] = []\n",
    "        missing_data_rows_dict[missing_field].append(row)\n",
    "    text_values = []\n",
    "    for field_value in fields:\n",
    "        parsed_list = parse_list_string(field_value)\n",
    "        text_values.extend(parsed_list)\n",
    "    text_representation = ' '.join(text_values).strip()\n",
    "    if not text_representation:\n",
    "        logging.warning(f\"Empty text representation for row with index {row.name}\")\n",
    "    return text_representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Define how plot labels are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom label generation function\n",
    "def label_func(row):\n",
    "    return f\"{row['id:ID']}, {row['name']}, custom label\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Process Models\n",
    "\n",
    "Generate and cache embeddings for your datasets using the `process_model` functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Generate or Load Embeddings for Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process embeddings for the datasets\n",
    "model_name, embeddings_dict = process_model(\n",
    "    model_name=model_name,\n",
    "    model_info=model_info,\n",
    "    datasets=datasets,\n",
    "    cache_dir=f'{cache_dir}/embeddings',\n",
    "    seed=seed2,\n",
    "    text_representation_func=node_to_string,\n",
    "    label_generation_func=label_func,\n",
    "    dataset_name=dataset_name,\n",
    "    use_ontogpt=False, # not working right now\n",
    "    cache_suffix=cache_suffix\n",
    ")\n",
    "# Reload embeddings after generation\n",
    "# embeddings_dict, labels_dict = load_embeddings_and_labels(\n",
    "#     cache_dir=f'{cache_dir}/embeddings',\n",
    "#     dataset_name=dataset_name,\n",
    "#     model_name=model_name,\n",
    "#     categories=categories,\n",
    "#     seed=seed2,\n",
    "#     combinations=False,\n",
    "#     cache_suffix=cache_suffix\n",
    "# )\n",
    "\n",
    "# Process embeddings for positive datasets\n",
    "model_name, embeddings_dict_pos = process_model(\n",
    "    model_name=model_name,\n",
    "    model_info=model_info,\n",
    "    datasets=positive_datasets,\n",
    "    cache_dir=f'{cache_dir}/embeddings',\n",
    "    seed=seed1,\n",
    "    text_representation_func=node_to_string,\n",
    "    label_generation_func=label_func,\n",
    "    dataset_name=dataset_name,\n",
    "    use_ontogpt=False, # not working right now\n",
    "    cache_suffix=cache_suffix\n",
    ")\n",
    "# Reload embeddings after generation\n",
    "# embeddings_dict_pos, labels_dict_pos = load_embeddings_and_labels(\n",
    "#     cache_dir=f'{cache_dir}/embeddings',\n",
    "#     dataset_name=dataset_name,\n",
    "#     model_name=model_name,\n",
    "#     categories=categories,\n",
    "#     seed=seed1,\n",
    "#     combinations=False,\n",
    "#     cache_suffix=cache_suffix\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Generate or Load Embeddings with Combinations (Optional)\n",
    "experimental, my attempt at generating sets of multiple embeddings for each node based on different combinations of features. probably semi useless, enhancing the node text representation using an LLM would probably be more useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define custom text representations for combinations\n",
    "# def node_to_strings(row):\n",
    "#     names_field = 'name'\n",
    "#     categories_field = 'category'\n",
    "#     names_field_value = row.get(names_field, '')\n",
    "#     categories_field_value = row.get(categories_field, '')\n",
    "    \n",
    "#     names_list = parse_list_string(names_field_value)\n",
    "#     categories_list = parse_list_string(categories_field_value)\n",
    "    \n",
    "#     from itertools import product\n",
    "#     combinations = list(product(names_list, categories_list))\n",
    "    \n",
    "#     text_representations = [' '.join(combination).strip() for combination in combinations]\n",
    "#     return text_representations\n",
    "\n",
    "# # Generate embeddings with combinations\n",
    "# model_name, embeddings_dict = process_model_combinations(\n",
    "#     model_name=model_name,\n",
    "#     model_info=model_info,\n",
    "#     datasets=datasets,\n",
    "#     cache_dir=cache_dir,\n",
    "#     seed=seed2,\n",
    "#     text_representation_func=node_to_strings,\n",
    "#     label_generation_func=label_func,\n",
    "#     dataset_name=dataset_name\n",
    "# )\n",
    "\n",
    "# Process embeddings for positive datasets with combinations\n",
    "# model_name, embeddings_dict_pos = process_model_combinations(\n",
    "#     model_name=model_name,\n",
    "#     model_info=model_info,\n",
    "#     datasets=positive_datasets,\n",
    "#     cache_dir=cache_dir,\n",
    "#     seed=seed1,\n",
    "#     text_representation_func=node_to_strings,\n",
    "#     label_generation_func=label_func,\n",
    "#     dataset_name=dataset_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example visualization code (e.g., using matplotlib or a dashboard app)\n",
    "# This is a placeholder; replace with your visualization code\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For example, visualize embeddings for 'All Categories'\n",
    "category = 'All Categories'\n",
    "embeddings = embeddings_dict[category]\n",
    "labels = labels_dict[category]\n",
    "\n",
    "# Use dimensionality reduction for visualization\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "reduced_embeddings = PCA(n_components=2).fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], alpha=0.5)\n",
    "plt.title(f'Embeddings Visualization for {category}')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Running the Dashboard App\n",
    "\n",
    "After generating the embeddings, you can use the dashboard app to visualize them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Instructions to Run the Dashboard App\n",
    "\n",
    "1. Ensure that the embeddings have been generated and saved in the cache directory.\n",
    "2. Navigate to the directory containing `app.py`.\n",
    "3. Run the app using the command:\n",
    "   ```\n",
    "   python app.py\n",
    "   ```\n",
    "4. Open the provided URL (usually `http://0.0.0.0:3000`) in your web browser.\n",
    "\n",
    "The dashboard should now display the embeddings and allow you to interact with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Adding New Models\n",
    "\n",
    "To add new models, update the `embedding_models_info` dictionary in `embedding_utils.py` with the details of the new model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Example: Adding a New Hugging Face Model\n",
    "\n",
    "```python\n",
    "# In embedding_utils.py\n",
    "embedding_models_info = {\n",
    "    'OpenAI': {\n",
    "        'type': 'openai',\n",
    "    },\n",
    "    'YourModelName': {\n",
    "        'type': 'hf',\n",
    "        'tokenizer_name': 'your-model-tokenizer-name',\n",
    "        'model_name': 'your-model-name'\n",
    "    },\n",
    "}\n",
    "```\n",
    "\n",
    "After updating, you can regenerate embeddings for the new model using the same process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
